Moment bounds in spdeâ€™s with application to
the stochastic wave equation
Le Chenâˆ— and Robert C. Dalangâˆ—
Institut de matheÌmatiques

arXiv:1401.6506v1 [math.PR] 25 Jan 2014

EÌcole Polytechnique FeÌdeÌrale de Lausanne
Station 8
CH-1015 Lausanne
Switzerland
e-mails: le.chen@epfl.ch, robert.dalang@epfl.ch

Abstract: We exhibit a class of properties of an spde that guarantees existence,
uniqueness and bounds on moments of the solution. These moment bounds are expressed in terms of quantities related to the associated deterministic homogeneous
p.d.e. With these, we can, for instance, obtain solutions to the stochastic heat
equation on the real line for initial data that falls in a certain class of Schwartz
distributions, but our main focus is the stochastic wave equation on the real line
with irregular initial data. We give bounds on higher moments, and for the hyperbolic Anderson model, explicit formulas for second moments. We establish weak
intermittency and obtain sharp bounds on exponential growth indices for certain
classes of initial conditions with unbounded support. Finally, we relate HoÌˆldercontinuity properties of the stochastic integral part of the solution to the stochastic
wave equation to integrability properties of the initial data, obtaining the optimal
HoÌˆlder exponent.
MSC 2010 subject classifications: Primary 60H15. Secondary 60G60, 35R60.
Keywords: nonlinear stochastic wave equation, hyperbolic Anderson model, intermittency, growth indices, HoÌˆlder continuity.

1

Introduction

Consider a partial differential operator L in the time and space variables (t, x) and a spacetime white noise WÌ‡ (t, x), where t âˆˆ Râˆ—+ = R+ \ {0} and x âˆˆ Rd , along with a function Î¸(t, x).
âˆ—

Research partially supported by the Swiss National Foundation for Scientific Research.

1

We are interested in determining when the stochastic partial differential equation (spde)
Lu(t, x) = Ï (u(t, x)) Î¸(t, x)WÌ‡ (t, x) ,

x âˆˆ Rd , t âˆˆ Râˆ—+ ,

(1.1)

with appropriate initial conditions, admits as solution a random field (u(t, x), (t, x) âˆˆ R+ Ã—
Rd ). In this case, we would like estimates and asymptotic properties of moments of u(t, x), as
well as HoÌˆlder-continuity properties. In this paper, we will develop such estimates for a wide
class of operators L, functions Î¸ and initial conditions, with an emphasis on the stochastic
wave and heat equations.
One basic example, which also was the starting point of this study, is the parabolic
âˆ‚2
âˆ‚
âˆ’Îº2 âˆ‚x
Anderson model. In this case, d = 1, L = âˆ‚t
2 , Ï(x) = Î»x and Î¸ â‰¡ 1. The intermittency
property of this equation, as defined in [7], is studied via the moment Lyapounov exponents,
in which estimates of the moments play a key role. Indeed, recall that the upper and lower
moment Lyapunov exponents for constant initial data are defined as follows:
mp (x) := lim sup
tâ†’+âˆ

log E [|u(t, x)|p ]
,
t

mp (x) := lim inf
tâ†’+âˆ

log E [|u(t, x)|p ]
.
t

(1.2)

If the initial conditions are constants, then mp (x) =: mp and mp (x) =: mp do not depend on
x. Intermittency is the property that mp = mp =: mp and m1 < m2 /2 < Â· Â· Â· < mp /p < Â· Â· Â· .
It is implied by the property m1 = 0 and m2 > 0 (see [7, Definition III.1.1, on p. 55]), which
is called full intermittency, while weak intermittency, defined in [29] and [17, Theorem 2.3]
is the property m2 > 0 and mp < +âˆ, for all p â‰¥ 2.
Another property of the parabolic Anderson model is described by the behavior of exponential growth indices, initiated by Conus and Khoshnevisan in [17]. They defined
(
)
1
(1.3)
Î»(p) := sup Î± > 0 : lim sup sup log E (|u(t, x)|p ) > 0 ,
tâ†’âˆ t |x|â‰¥Î±t
(
)
1
Î»(p) := inf Î± > 0 : lim sup sup log E (|u(t, x)|p ) < 0 ,
(1.4)
tâ†’âˆ t |x|â‰¥Î±t
This is again a property of moments of the solution u(t, x).
In the recent paper [11], in the case Î¸ â‰¡ 1, the authors have given minimal conditions on
the initial data for existence, uniqueness and moments estimates in the parabolic Anderson
model, building on the previous results of [2, 16]. The initial condition can be a signed
measure, but not a Schwartz distribution that is not a measure, such as the derivative Î´00 of
the Dirac delta function. Exact formulas for the second moments were determined for the
parabolic Anderson model, along with sharp bounds for other moments and choices of the
function Ï.
Our program is to extend these kinds of results to many other classes of spdeâ€™s. Recall
that an spde such as (1.1) is often rigorously formulated as an integral equation of the form
ZZ
u(t, x) = J0 (t, x) +
G(t âˆ’ s, x âˆ’ y)Ï(u(s, y))Î¸(s, y)W (ds, dy),
(1.5)
R+ Ã—Rd

2

where J0 : R+ Ã— Rd represents the solution of the (deterministic) homogeneous p.d.e. with
the appropriate initial conditions, and G(t, x) is the fundamental solution of the p.d.e. The
stochastic integral in (1.5) is defined in the sense of Walsh [46]. In a first stage, we shall
focus on the equation (1.5), for given functions J0 and G satisfying suitable assumptions,
even if they are not specifically related to a partial differential operator L. For this, the first
step is to develop a unified set of assumptions which are sufficient to guarantee the existence,
uniqueness and moment estimates of the solution to (1.1). All of these assumptions should
be satisfied for the J0 and G associated with the stochastic heat equation, so as to contain
the results of [11]. It will turn out that in fact, they can be verified for quite different
equations, such as the stochastic wave equation, which we discuss in this paper, and the
stochastic heat equation with fractional spatial derivatives as well as other equations, which
will be discussed in forthcoming papers.
The assumptions are given in Section 2.1. In particular, G must be a function with
certain continuity and integrability properties, and must satisfy certain bounds, including
tail control, and an L2 -continuity property. Another assumption relates properties of the
function J0 with those of G. Finally, a last set of assumptions concerns the function K
obtained by summing n-fold space-time convolutions of the square of G with itself.
Our first theorem (Theorem 2.13) states that under these assumptions, we obtain existence, uniqueness and moment bounds of the solution to (1.5). When particularized to the
stochastic heat equation, all the assumptions are satisfied and the bounds are the same as
those obtained in [11].
Recall that Î¸(t, x) â‰¡ 1 in [11]. Here, as an application of our first theorem, we will show
in Theorem 2.22 that by choosing Î¸ so that Î¸(t, x) â†’ 0 as t â†“ 0 (which means that we taper
off the noise near t = 0), we can extend the class of admissible initial conditions in the
stochastic heat equation beyond signed measures. And the more the noise near the origin is
killed, the more irregular the initial condition may be. The balance between the admissible
initial data and certain properties of the function Î¸ is stated in Theorem 2.22. For instance,
if Î¸(t, x) â‰¡ 1, then the initial data cannot go beyond measures; if Î¸(t, x) = tr âˆ§ 1 for some
(k)
(k)
r > 0, then the initial data can be Î´0 for all integers k âˆˆ [0, 2r + 1/2[ , where Î´0 is the
k-th distributional derivative of the Dirac delta function Î´0 ; if Î¸(t, x) = exp (âˆ’1/t), then any
Schwartz (or tempered) distribution can serve as the initial data (see Examples 2.24 and
2.25).
The second and main application in this paper of our first theorem concerns the stochastic
wave equation:

( 2
âˆ‚
2 âˆ‚2
âˆ’
Îº
u(t, x) = Ï(u(t, x)) WÌ‡ (t, x), x âˆˆ R, t âˆˆ Râˆ—+ ,
âˆ‚t2
âˆ‚x2
(1.6)
u(0, Â·) = g(Â·), âˆ‚u
(0,
Â·)
=
Âµ(Â·),
âˆ‚t
where Râˆ—+ = ]0, âˆ[ , WÌ‡ is space-time white noise, Ï(u) is globally Lipschitz, Îº > 0 is the
speed of wave propagation, g and Âµ are the (deterministic) initial position and velocity,
respectively. The linear case, Ï(u) = Î»u, Î» 6= 0, is called the hyperbolic Anderson model [23].
3

This equation has been intensively studied during last two decades by many authors:
see e.g., [6, 8, 9, 41, 46] for some early work, [20, 46] for an introduction, [23, 24] for the
intermittency problems, [15, 21, 22, 25, 35, 42, 43] for the stochastic wave equation in the
spatial domain Rd , d > 1, [26, 45] for regularity of the solution, [4, 5] for the stochastic
wave equation with values in Riemannian manifolds, [13, 39, 40] for wave equations with
polynomial nonlinearities, and [36, 37, 44] for smoothness of the law.
Concerning intermittency properties, Dalang and Mueller showed in [23] that for the wave
equation in spatial domain R3 with spatially homogeneous colored noise, with Ï(u) = u
and constant initial position and velocity, the Lyapunov exponents mp and mp are both
bounded, from above and below respectively, by some constant times p4/3 . For the stochastic
wave equation in spatial dimension 1, Conus et al [17] show that if the initial position
and velocity are bounded and measurable functions, then the moment Lyapunov exponents
satisfy mp â‰¤ Cp3/2 for p â‰¥ 2, and m2 â‰¥ c(Îº/2)1/2 for positive initial data. The difference in
the exponentsâ€”3/2 versus 4/3 in the three dimensional wave equationâ€”reflects the distinct
nature of the driving noises. Recently Conus and Balan [1] studied the problem when the
noise is Gaussian, spatially homogeneous and behaves in time like a fractional Brownian
motion with Hurst index H > 1/2.
Regarding exponential growth indices, Conus and Khoshnevisan [18, Theorem 5.1] show
that for initial data with exponential decay at Â±âˆ, 0 < Î»(p) â‰¤ Î»(p) < +âˆ, for all p â‰¥ 2.
They also show that if the initial data consists of functions with compact support, then
Î»(p) = Î»(p) = Îº, for all p â‰¥ 2.
One objective of our study is to understand how irregular (and possibly unbounded)
initial data affects the random field solutions to (1.6); another is to continue the study of
moment Lyapounov exponents and exponential growth indices of [17, 18]. We will only
assume that the initial position g belongs to L2loc (R), the set of locally square integrable
Borel functions, and the initial velocity Âµ belongs to M (R), the set of locally finite Borel
measures. These assumptions are natural since the weak solution to the homogeneous wave
equation is
J0 (t, x) :=

1
(g(x + Îºt) + g(x âˆ’ Îºt)) + (Âµ âˆ— GÎº (t, â—¦))(x) ,
2

(1.7)

where

1
GÎº (t, x) = H(t)1[âˆ’Îºt,Îºt] (x)
2
is the wave kernel function. Here, H(t) is the Heaviside function (i.e., H(t) = 1 if t â‰¥ 0 and
0 otherwise), and âˆ— denotes convolution in the space variable.
Regarding the spde (1.6), we interpret it in the integral (mild) form (1.5):
u(t, x) = J0 (t, x) + I(t, x),
where
I(t, x) :=

ZZ

[0,t]Ã—R

GÎº (t âˆ’ s, x âˆ’ y) Ï (u (s, y)) W (ds, dy) .
4

(1.8)

We show that all the assumptions of Section 2.1 are verified for this equation. More
importantly, the abstract bounds take an explicit form since the function K can be evaluated
explicitly (see Theorem 3.1). This was also the case for the stochastic heat equation [11],
but the formula for K here is quite different than in this reference. We also obtain explicit
formulas for the second moment of the solution in the hyperbolic Anderson model, as well
as sharp bounds for higher moments. These bounds also apply to other choices of Ï. For
some particular choices of initial data (such as constant initial position and velocity, or
vanishing initial position and Dirac initial velocity), the second moment of the solution
takes a particularly simple form (see Corollaries 3.2 and 3.3 below).
As an immediate consequence of Theorem 3.1, we obtain the result mp â‰¤ Cp3/2 for p â‰¥ 2
of [17] (see Theorem 3.11). We extend their lower bound on the upper Lyapunov exponent
m2 to the lower Lyapounov exponent, by showing that m2 â‰¥ c(Îº/2)1/2 . In the case of the
Anderson model Ï(u) = Î»u, we show that m2 = m2 = |Î»| (Îº/2)1/2 .
Concerning exponential growth indices, we use Theorem 3.1 to give specific upper and
lower bounds on these indices. For instance, we show in Theorem 3.14 that if the initial
position and velocity are bounded below by ceâˆ’Î²|x| and above by Ceâˆ’Î²Ìƒ|x| , with Î² â‰¥ Î²Ìƒ, then


l2
Îº 1+
8ÎºÎ² 2

 12



L2
â‰¤ Î»(p) â‰¤ Î»(p) â‰¤ Îº 1 +
8ÎºÎ²Ìƒ 2

 12

,

for certain explicit constants l and L. In the case of the Anderson model Ï(u) = Î»u and for
p = 2 and Î² = Î²Ìƒ, we obtain


Î»2
Î»(2) = Î»(2) = Îº 1 +
8ÎºÎ² 2

1/2

.

Since the exponential growth indices of order 2 depend on the asymptotic behavior of
E(u(t, x)2 ) as t â†’ âˆ, this equality highlights, in a somewhat surprising way, how the
initial data significantly affects the behavior of the solution for all time, despite the presence
of the driving noise.
A final question concerns the sample path regularity properties. Denote by CÎ²1 ,Î²2 (D) the
set of trajectories that are Î²1 -HoÌˆlder continuous in time and Î²2 -HoÌˆlder continuous in space
on the domain D âŠ† R+ Ã— R, and let
CÎ²1 âˆ’,Î²2 âˆ’ (D) := âˆ©Î±1 âˆˆ ]0,Î²1 [ âˆ©Î±2 âˆˆ ]0,Î²2 [ CÎ±1 ,Î±2 (D) .
Carmona and Nualart [9, p.484â€“485] showed that if the initial position is constant and the
initial velocity vanishes, then the solution is in C1/2âˆ’,1/2âˆ’ (R+ Ã— R) a.s. This property can
also be deduced from [45, Theorem 4.1]. The case where the spatial domain is R3 has been
studied in [26, 20].
In [17], Conus et al establish HoÌˆlder-continuity properties of x 7â†’ u(t, x) (t fixed). In
particular, they show that if the initial position g is a 1/2-HoÌˆlder-continuous function and
the initial velocity is square-integrable, then x 7â†’ u(t, x) is ( 21 âˆ’ )-HoÌˆlder-continuous. The
5

assumption on the initial data is needed, since the HoÌˆlder-continuity properties of the initial
position are not smoothed out by the wave kernel but are transferred to J0 (t, x) via formula
(1.7).
A related question concerns the stochastic term I(t, x) of (1.8), which represents the
difference u(t, x)âˆ’J0 (t, x) between the solution of (1.6) and the solution to the homogeneous
wave equation. We are interested in understanding how properties of the initial data affect
the regularity of (t, x) 7â†’ I(t, x). We show in Theorem 4.1 that the better the (local)
integrability properties of the initial position g, the better the regularity of (t, x) 7â†’ I(t, x).
In particular, if g âˆˆ L2Î³
loc (R), Î³ â‰¥ 1, and Âµ âˆˆ M(R), then (t, x) 7â†’ I(t, x) belongs to
âˆ—
C 1 0 âˆ’, 1 0 âˆ’ R+ Ã— R , where Î³1 + Î³10 = 1. We show in Proposition 4.2 that the HoÌˆlder-exponents
2Î³

2Î³

1
2Î³ 0

are optimal.
This paper is organized as follows. In Section 2, we study our abstract integral equation
and present the main result in Theorem 2.13. The application to the stochastic heat equation
with distribution-valued initial data is given in Section 2.3. Section 3 contains the application
to the stochastic wave equation. The main results on existence, uniqueness and formulas
and bounds on moments are stated in Section 3.1 and proved in Section 3.2. The weak
intermittency property is established in Section 3.3. The bounds on exponential growth
indices are given in Section 3.4, and proved in Section 3.5. Finally, Section 4 contains our
results on HoÌˆlder continuity of the solution of the stochastic wave equation.

2

Stochastic integral equation of space-time convolution type

We begin by stating the main assumptions which will be needed in our theorem on existence,
uniqueness and moment bounds.

2.1

Assumptions



Let Wt (A) : A âˆˆ Bb Rd , t â‰¥ 0 be a space-time white noise defined on a complete probability space (â„¦, F, P ), where Bb Rd is the collection of Borel sets with finite Lebesgue
measure. Let (Ft , t â‰¥ 0) be the standard filtration
generated by this space-time white

d
âˆ¨ N , where N is the Ïƒ-field generated
noise, i.e., Ft = Ïƒ Ws (A) : 0 â‰¤ s â‰¤ t, A âˆˆ Bb R
by all P -null sets in F. We use ||Â·||p to denote the Lp (â„¦)-norm. A random field Y (t, x),
(t, x) âˆˆ Râˆ—+ Ã— Rd , is said to be adapted if for all (t, x) âˆˆ Râˆ—+ Ã— Rd , Y (t, x) is Ft -measurable,
and it is said to be jointly measurable if it is measurable with respect to B(Râˆ—+ Ã— Rd ) Ã— F.
For p â‰¥ 2, if lim(t0 ,x0 )â†’(t,x) ||Y (t, x) âˆ’ Y (t0 , x0 )||p = 0 for all (t, x) âˆˆ Râˆ—+ Ã— Rd , then Y is said
to be Lp (â„¦)-continuous.
Let G, J0 : R+ Ã— Rd 7â†’ R be deterministic Borel functions. We use the convention that
G(t, Â·) â‰¡ 0 if t â‰¤ 0. In the following, we will use Â· and â—¦ to denote the time and space dummy
variables respectively.
6

Definition 2.1. A random field (u(t, x), (t, x) âˆˆ R+ Ã— Rd ), is called a solution to (1.5) if
(1) u(t, x) is adapted and jointly measurable;


(2) For all (t, x) âˆˆ Râˆ—+ Ã— Rd , G2 (Â·, â—¦) ? ||Ï(u(Â·, â—¦))||22 Î¸2 (Â·, â—¦) (t, x) < +âˆ, where ? denotes
the simultaneous convolution in both space and time variables, and the function (t, x) 7â†’
I(t, x) from R+ Ã— Rd into L2 (â„¦) is continuous;
(3) u(t, x) = J0 (t, x) + I(t, x), where for all (t, x) âˆˆ R+ Ã— Rd ,
ZZ
I(t, x) =
G (t âˆ’ s, x âˆ’ y) Ï (u (s, y)) Î¸ (s, y) W (ds, dy) ,

a.s.

(2.1)

R+ Ã—Rd

We call I(t, x) the stochastic integral part of the random field solution. This stochastic
integral is interpreted in the sense of Walsh [46].
Remark 2.2. Consider the stochastic wave equation (1.6) with g âˆˆ L2loc (R) and Âµ = 0.
In this case, J0 (t, x) = 1/2 (g(Îºt + x) + g(Îºt âˆ’ x)). Since the initial position g may not
be defined for every x, the function (t, x) 7â†’ J0 (t, x) may not be defined for certain (t, x).
Therefore, for these (t, x), u(t, x) may not be well-defined (see Example 3.4). Nevertheless,
as we will show later, I(t, x) is always well defined for each (t, x) âˆˆ R+ Ã— R, and in most
cases (when Assumption 2.14 below holds), it has a continuous version. Finally, we remark
that for the stochastic heat equation with deterministic initial conditions, this problem does
not arise because in that equation, (t, x) 7â†’ J0 (t, x) is continuous over Râˆ—+ Ã— R thanks to the
smoothing effect of the heat kernel.
As in [21], a very first issue is whether the linear equation, where Ï(u) â‰¡ 1, admits a
random field solution. For t âˆˆ R+ , and x, y âˆˆ Rd , this leads to examining the quantity
ZZ
Î˜(t, x, y) :=
dsdz G(t âˆ’ s, x âˆ’ z)G (t âˆ’ s, y âˆ’ z) Î¸2 (s, z) .
(2.2)
[0,t]Ã—Rd

Clearly, 2Î˜(t, x, y) â‰¤ Î˜(t, x, x) + Î˜ (t, y, y).
Assumption 2.3. G(t, x) is such that
(i) Î˜(t, x, x) < +âˆ for all (t, x) âˆˆ R+ Ã— Rd ;
(ii) lim(t0 ,x0 )â†’(t,x) G (t0 , x0 ) = G(t, x), for almost all (t, x) âˆˆ R+ Ã— Rd .
âˆ‚
If Î¸(t, x) â‰¡ 1, d = 1 and if the underlying partial differential operator is âˆ‚t
âˆ’ A, where A
is the generator of a real-valued
LeÌvy process with the LeÌvy exponent Î¨(Î¾), then Assumption
R
dÎ¾
1
2.3 (i) is equivalent to 2Ï€
< +âˆ, for all Î² > 0, where <Î¨(Î¾) is the real part of
R Î²+2<Î¨(Î¾)
Î¨(Î¾): see [21, 29]. For the one-dimensional stochastic heat equation studied in [11], it is
also clearly satisfied. For the stochastic wave equation (1.6), this assumption also holds: see
(3.6).

7

Assumption 2.4. For all compact sets K âŠ† Râˆ—+ Ã— Rd and all integers p â‰¥ 2,

 

1 + J02 Î¸2 ? G2 (t, x) < +âˆ.
sup
(t,x)âˆˆK

We note that a related assumption appears in [9, Proposition 1.8]. The next three
assumptions will be used to establish the Lp (â„¦)-continuity in a Picard iteration. Assumption
2.5 is for kernel functions similar to the wave kernel and Assumptions 2.6â€“2.8 are for those
similar to the heat kernel. We need some notation: for Î² âˆˆ ]0, 1[ , Ï„ > 0, Î± > 0 and
(t, x) âˆˆ Râˆ—+ Ã— Rd , define

Bt,x,Î²,Ï„,Î± := (t0 , x0 ) âˆˆ Râˆ—+ Ã— Rd : Î²t â‰¤ t0 â‰¤ t + Ï„, |x âˆ’ x0 | â‰¤ Î± .
(2.3)
Assumption 2.5 (Uniformly bounded kernel functions). There exist three constants Î² âˆˆ
]0, 1[ , Ï„ > 0 and Î± > 0 such that for all (t, x) âˆˆ Râˆ—+ Ã— Rd , for some constant C > 0, we have
for all (t0 , x0 ) âˆˆ Bt,x,Î²,Ï„,Î± and all (s, y) âˆˆ [0, t0 [Ã—Rd , G(t0 âˆ’ s, x0 âˆ’ y) â‰¤ C G(t + 1 âˆ’ s, x âˆ’ y).

Assumption 2.6 (Tail control of kernel functions). There exists Î² âˆˆ ]0, 1[ such that for
all (t, x) âˆˆ Râˆ—+ Ã— Rd , for some constant a > 0, we have for all (t0 , x0 ) âˆˆ Bt,x,Î²,1/2,1 and all
s âˆˆ [0, t0 [ and y âˆˆ Rd with |y| â‰¥ a, G(t0 âˆ’ s, x0 âˆ’ y) â‰¤ G(t + 1 âˆ’ s, x âˆ’ y).
Assumption 2.7. For all (t, x) âˆˆ Râˆ—+ Ã— Rd ,
ZZ
2
lim
dsdy Î¸(s, y)2 (G(t0 âˆ’ s, x0 âˆ’ y) âˆ’ G (t âˆ’ s, x âˆ’ y)) = 0.
0 0
(t ,x )â†’(t,x)

R+ Ã—Rd

Note that this assumption can be more explicitly expressed in the following way:
Z tâˆ—
0

ds

Z

Rd

2

dy Î¸(s, y)2 (G(t0 âˆ’ s, x0 âˆ’ y) âˆ’ G (t âˆ’ s, x âˆ’ y))
+

Z tÌ‚

ds

tâˆ—

as (t0 , x0 ) â†’ (t, x), where
(
(t0 , x0 ) if t0 â‰¤ t,
( tâˆ— , xâˆ— ) =
(t, x) if t0 > t,

and

Z

Rd


dy Î¸(s, y)2 G2 tÌ‚ âˆ’ s, xÌ‚ âˆ’ y â†’ 0, (2.4)
(
(t, x) if t0 â‰¤ t.
tÌ‚, xÌ‚ =
(t0 , x0 ) if t0 > t.


(2.5)

Assumption 2.8. For all compact sets K âŠ† Râˆ—+ Ã— Rd , sup(t,x)âˆˆK |J0 (t, x)| < âˆ.
The remaining assumptions are mainly needed for control of the moments of the solution.
We introduce some notation. For two functions f, g : R+ Ã— Rd 7â†’ R+ , define their Î¸-weighted
space-time convolution by
 
(f B g) (t, x) := Î¸2 f ? g (t, x), for all (t, x) âˆˆ R+ Ã— Rd ,
8

In the following, f (t, x) will play the role of J02 (t, x), and g(t, x) of G2 (t, x). In the Picard
iteration scheme, the expression ((Â· Â· Â· ((f B g1 ) B g2 ) B Â· Â· Â· ) B gn ) (t, x) will appear, where
gi = g. Since B is not associative in general (contrary to the case Î¸ â‰¡ 1), we need to handle
this formula with care.
Definition 2.9. Let n â‰¥ 2 and let gk : R+ Ã— Rd 7â†’ R+ , k = 1, . . . , n. Define the Î¸-weighted
multiple space-time convolution, for (t, x), (s, y) âˆˆ R+ Ã— Rd with 0 â‰¤ s â‰¤ t, by
Bn (g1 , g2 , . . . , gn ) (t, x; s, y)
Z
Z s
dsnâˆ’1
dynâˆ’1 gn (s âˆ’ snâˆ’1 , y âˆ’ ynâˆ’1 ) Î¸2 (t âˆ’ s + snâˆ’1 , x âˆ’ y + ynâˆ’1 )
:=
d
0
Z snâˆ’1 R
Z
dsnâˆ’2
Ã—
dynâˆ’2 gnâˆ’1 (snâˆ’1 âˆ’ snâˆ’2 , ynâˆ’1 âˆ’ ynâˆ’2 ) Î¸2 (t âˆ’ s + snâˆ’2 , x âˆ’ y + ynâˆ’2 )
d
0
Z sR3
Z
ds2
Ã— Â·Â·Â·Â·Â·Â· Ã—
dy2 g3 (s3 âˆ’ s2 , y3 âˆ’ y2 ) Î¸2 (t âˆ’ s + s2 , x âˆ’ y + y2 )
Rd
Z0
Z s2
ds1
dy1 g2 (s2 âˆ’ s1 , y2 âˆ’ y1 ) Î¸2 (t âˆ’ s + s1 , x âˆ’ y + y1 ) g1 (s1 , y1 ) .
(2.6)
Ã—
0

Rd

Notice that
Bn (g1 , . . . , gn ) (t, x; t, x) = ((Â· Â· Â· ((g1 B g2 ) B g3 ) B Â· Â· Â· ) B gn ) (t, x),
where the r.h.s. has n âˆ’ 1 convolutions. By the change of variables
Ï„1 = s âˆ’ snâˆ’1 , Ï„2 = s âˆ’ snâˆ’2 , Â· Â· Â· , Ï„nâˆ’1 = s âˆ’ s1 ,
z1 = y âˆ’ ynâˆ’1 , z2 = y âˆ’ ynâˆ’2 , Â· Â· Â· , znâˆ’1 = y âˆ’ y1 ,

and

(2.7)

and Fubiniâ€™s theorem, the multiple convolution Bn has an equivalent definition:
Bn (g1 , g2 , . . . , gn ) (t, x; s, y)
Z s
Z
=
dÏ„nâˆ’1
dznâˆ’1 Î¸2 (t âˆ’ Ï„nâˆ’1 , x âˆ’ znâˆ’1 ) g1 (s âˆ’ Ï„nâˆ’1 , y âˆ’ znâˆ’1 )
d
0
Z Ï„nâˆ’1 R Z
Ã—
dÏ„nâˆ’2
dznâˆ’2 Î¸2 (t âˆ’ Ï„nâˆ’2 , x âˆ’ znâˆ’2 ) g2 (Ï„nâˆ’1 âˆ’ Ï„nâˆ’2 , znâˆ’1 âˆ’ znâˆ’2 )
d
0
Z Ï„3 R Z
Ã— Â·Â·Â·Â·Â·Â· Ã—
dÏ„2
dz2 Î¸2 (t âˆ’ Ï„2 , x âˆ’ z2 ) gnâˆ’2 (Ï„3 âˆ’ Ï„2 , z3 âˆ’ z2 )
d
R
Z Ï„2
Z0
2
Ã—
dÏ„1
dz1 Î¸ (t âˆ’ Ï„1 , x âˆ’ z1 ) gnâˆ’1 (Ï„2 âˆ’ Ï„1 , z2 âˆ’ z1 ) gn (Ï„1 , z1 ) .
0

(2.8)

Rd

Lemma 2.10. Let f, gk : R+ Ã— Rd 7â†’ R+ , k = 1, . . . , n + 1, and n â‰¥ 2. Then for all
(t, x) âˆˆ R+ Ã— Rd , we have
((Â· Â· Â· ((f B g1 ) B g2 ) B Â· Â· Â· ) B gn ) (t, x) = (f B Bn (g1 , . . . , gn ) (t, x; Â·, â—¦)) (t, x),
9

(2.9)

(f B Bn (g1 , . . . , gn ) (t, x; Â·, â—¦)) (t, x) = ((f B g1 ) B Bnâˆ’1 (g2 , . . . , gn ) (t, x; Â·, â—¦)) (t, x), (2.10)
and
Z t
0

ds

Z

Rd

dy (f B Bn (g1 , . . . , gn ) (s, y; Â·, â—¦)) (s, y) Î¸2 (s, y)gn+1 (t âˆ’ s, x âˆ’ y)
= (f B Bn+1 (g1 , . . . , gn+1 ) (t, x; Â·, â—¦)) (t, x). (2.11)

Note that (s, y) appears twice in the term f B Bn (Â· Â· Â· ) on the l.h.s. of (2.11). The proof
of Lemma 2.10 is straightforward; see [10, Lemma 3.2.6] for details. When n = 2, for f and
g : R+ Ã— Rd 7â†’ R+ , B2 (f, g)(t, x; t, x) = (f B g) (t, x) and
Z
Z s
ds0
dy0 g (s âˆ’ s0 , y âˆ’ y0 ) Î¸2 (t âˆ’ s + s0 , x âˆ’ y + y0 ) f (s0 , y0)
B2 (f, g) (t, x; s, y) =
Rd

0

=

Z s
0

dÏ„0

Z

Rd

(2.12)

dz0 Î¸2 (t âˆ’ Ï„0 , x âˆ’ z0 ) f (s âˆ’ Ï„0 , y âˆ’ z0 ) g (Ï„0 , z0 ) .

(2.13)

In particular, if Î¸(t, x) â‰¡ 1, then B2 reduces to the standard space-time convolution ? (as is
the case for B), in which case the first two variables (t, x) do not play a role. We call (2.12)
and (2.6) the forward formulas, and (2.13) and (2.8) the backward formulas.
For Î» âˆˆ R, define L0 (t, x; Î») := Î»2 G2 (t, x), and for n âˆˆ Nâˆ— ,

Ln (t, x; s, y; Î») := Bn+1 L0 (Â·, â—¦; Î»), . . . , L0 (Â·, â—¦; Î») (t, x; s, y)
for all (t, x), (s, y) âˆˆ Râˆ—+ Ã— Rd with s â‰¤ t. By convention, L0 (t, x; s, y; Î») = Î»2 G2 (s, y). For
n âˆˆ N, define
Hn (t, x; Î») := (1 B Ln (t, x; Â·, â—¦; Î»)) (t, x) .
By definition, both Ln and Hn are non-negative. We use the following conventions:
Ln (t, x; s, y) := Ln (t, x; s, y; Î») ,

Ln (t, x; s, y) := K (t, x; s, y; LÏ ) ,
(2.14)
Ln (t, x; s, y) := Ln (t, x; s, y; l Ï ) , Lbn (t, x; s, y) := Ln (t, x; s, y; ap,Ï‚ zp LÏ ) , p â‰¥ 2 ,

where the constant ap,Ï‚ (â‰¤ 2) is defined by
ï£±
(pâˆ’1)/p
ï£´
ï£²2âˆš
ap,Ï‚ :=
2
ï£´
ï£³
1

Ï‚ 6= 0, p > 2,
Ï‚ = 0, p > 2,
p = 2,

(2.15)

and zp is the optimal universal constant in the Burkholder-Davis-Gundy inequality (see
âˆš
[18, Theorem 1.4]) and so z2 = 1 and zp â‰¤ 2 p for all p â‰¥ 2. Note that the kernel
function Lbn (t, x; s, y) depends on the parameters p and Ï‚, which is usually clear from the
bn (t, x). The same conventions will apply
context. Similarly, define Hn (t, x), Hn (t, x) and H
b (t, x; s, y) below.
to K (t, x; s, y), K (t, x; s, y), K (t, x; s, y) and K
10

Assumption 2.11. The kernel functions Ln (t, x; s, y; Î») and Hn (t, x; s; Î»), with n âˆˆ N
and Î» âˆˆ R, are well defined and the sum of Ln (t, x; s, y; Î») converges for all (t, x) and
(s, y) âˆˆ Râˆ—+ Ã— Rd with s â‰¤ t. Denote this sum by
K (t, x; s, y; Î») :=

âˆ
X
n=0

Ln (t, x; s, y; Î») .

The next assumption is a convenient assumption which will guarantee the continuity of
the function (t, x) 7â†’ I(t, x) from R+ Ã— Rd into Lp (â„¦) for p â‰¥ 2.
Assumption 2.12. There are non-negative functions Bn (t) := Bn (t; Î») such that (i) Bn (t)
is nondecreasing in t; (ii) for all (t, x), (s, y)
âˆˆ Râˆ—+ Ã— Rd with s â‰¤ t and n âˆˆ N, Ln (t, x; s, y) â‰¤
Pâˆ p
L0 (s, y) Bn (t) (set B0 (t) â‰¡ 1); (iii) n=0 Bn (t) < +âˆ, for all t > 0.

The above assumption guarantees that the following function (without any square root)
is well defined:
Î¥ (t; Î») :=

âˆ
X

Bn (t; Î») ,

n=0

t â‰¥ 0.

(2.16)

We use the same conventions on the parameter Î» for the function Î¥(t; Î»). Clearly, for all
(t, x) and (s, y) âˆˆ R+ Ã— Rd such that s â‰¤ t,
K (t, x; s, y) â‰¤ Î¥(t)L0 (s, y) .
(2.17)
P
Another consequence of Assumption 2.12 is that âˆ
n=0 Hn (t, x) â‰¤ H0 (t, x)Î¥(t) < +âˆ for
d
all (t, x) âˆˆ R+ Ã— R andP
0 â‰¤ s â‰¤ t, and so the function H(t, x) := (1 B K(t, x; Â·, â—¦)) (t, x) is
well defined and equals âˆ
n=0 Hn (t, x) by the monotone convergence theorem.
The following chain of inequalities is a direct consequence of Assumption 2.3 and the
observations above: for all n âˆˆ N, and all (t, x), (s, y) âˆˆ Râˆ—+ Ã— Rd with s â‰¤ t,



J02 B Ln (t, x; Â·, â—¦) (t, x) â‰¤ J02 B K(t, x; Â·, â—¦) (t, x) â‰¤ Î¥(t) J02 B L0 (t, x) < +âˆ . (2.18)

2.2

Main theorem

Assume that Ï : R 7â†’ R is globally Lipschitz continuous with Lipschitz constant LipÏ > 0.
We need some growth conditions on Ï: Assume that for some constants LÏ > 0 and Ï‚ â‰¥ 0,

|Ï(x)|2 â‰¤ L2Ï Ï‚ 2 +x2 ,
for all x âˆˆ R ,
(2.19)
âˆš
Note that LÏ â‰¤ 2 LipÏ , and the inequality may be strict. In order to bound the second
moment from below, we will sometimes assume that for some constants l Ï > 0 and Ï‚ â‰¥ 0,

|Ï(x)|2 â‰¥ l 2Ï Ï‚ 2 +x2 ,
for all x âˆˆ R .
(2.20)
11

We shall also give particular attention to the Anderson model, which is a special case of the
following quasi-linear growth condition: for some constants Ï‚ â‰¥ 0 and Î» 6= 0,

|Ï(x)|2 = Î»2 Ï‚ 2 +x2 ,
for all x âˆˆ R .
(2.21)
To facilitate stating the theorem, we group the assumptions above as follows:

(G) (General conditions):
(a) G(t, x) satisfies Assumptions 2.3, 2.11, and 2.12;
(b) J0 (t, x) and Î¸(t, x) satisfy Assumption 2.4.
(W) (Wave type) G(t, x) satisfies Assumptions 2.5.
(H) (Heat type):
(a) G(t, x) satisfies Assumptions 2.6 and 2.7;
(b) J0 (t, x) satisfies Assumption 2.8.
Theorem 2.13. Suppose the function Ï(u) is Lipschitz continuous and satisfies the growth
condition (2.19). If (G) and at least one of (W) and (H) hold, then the stochastic integral
equation (1.5) has a solution

u(t, x) = J0 (t, x) + I(t, x) : t > 0, x âˆˆ Rd
in the sense of Definition 2.1. This solution has the following properties:
(1) I(t, x) is unique (in the sense of versions).
(2) I(t, x) is Lp (â„¦)â€“continuous over R+ Ã— Rd for all integers p â‰¥ 2.
(3) For all even integers p â‰¥ 2, t > 0, and x, y âˆˆ Rd ,
ï£±

if p = 2,
ï£²J02 (t, x) + J02 B K(t, x; Â·, â—¦) (t, x) + Ï‚ 2 H(t, x),
2


||u(t, x)||p â‰¤
ï£³2J 2 (t, x) + 2J 2 B K(t,
b x; Â·, â—¦) (t, x) + Ï‚ 2 H(t,
b x), if p > 2,
0
0

(2.22)

and

E [u(t, x)u(t, y)] â‰¤ J0 (t, x)J0 (t, y) + L2Ï Ï‚ 2 Î˜(t, x, y)
Z t Z
2
+ LÏ
ds
dz f (s, z) Î¸2 (s, z) G(t âˆ’ s, x âˆ’ z)G (t âˆ’ s, y âˆ’ z) , (2.23)
0

Rd

where f (s, z) denotes the r.h.s. of (2.22) for p = 2.
(4) If Ï satisfies (2.20), then for all t > 0, and x, y âˆˆ Rd ,

||u(t, x)||22 â‰¥ J02 (t, x) + J02 B K(t, x; Â·, â—¦) (t, x) + Ï‚ 2 H(t, x),
12

(2.24)

and
E [u(t, x)u(t, y)] â‰¥ J0 (t, x)J0 (t, y) + l 2Ï Ï‚ 2 Î˜(t, x, y)
Z t Z
2
ds
dz f (s, z) Î¸2 (s, z) G(t âˆ’ s, x âˆ’ z)G (t âˆ’ s, y âˆ’ z) , (2.25)
+ lÏ
0

Rd

where f (s, z) denotes the r.h.s. of (2.24).
(5) In particular, for the quasi-linear case |Ï(u)|2 = Î»2 (Ï‚ 2 +u2 ), for all t > 0, x, y âˆˆ Rd ,

||u(t, x)||22 = J02 (t, x) + J02 B K(t, x; Â·, â—¦) (t, x) + Ï‚ 2 H(t, x),
(2.26)
and

E [u(t, x)u(t, y)] = J0 (t, x)J0 (t, y) + Î»2 Ï‚ 2 Î˜(t, x, y)
Z t Z
2
+Î»
ds
dz f (s, z) Î¸2 (s, z) G(t âˆ’ s, x âˆ’ z)G (t âˆ’ s, y âˆ’ z) , (2.27)
0

Rd

where f (s, z) = ||u(s, z)||22 is given in (2.26).
We now present an assumption that will imply HoÌˆlder continuity of the stochastic integral
part of the solution u of (1.5).
Assumption 2.14. (Sufficient conditions for HoÌˆlder continuity) Given J0 (t, x) and v âˆˆ R,
assume that there are d + 1 constants Î³i âˆˆ ]0, 1], i = 0, . . . , d such that for all n > 1, one can
find a finite constant Cn < +âˆ such that for all (t, x) and (t0 , x0 ) âˆˆ Kn := [1/n, n] Ã— [âˆ’n, n]d
with t < t0 , we have that
ZZ
and
ZZ

R+ Ã—Rd


2
dsdy v 2 + 2J02 (s, y) (G (t âˆ’ s, x âˆ’ y) âˆ’ G(t0 âˆ’ s, x0 âˆ’ y)) Î¸2 (s, y)

â‰¤ Cn Ï„Î³0 ,...,Î³d ((t, x), (t0 , x0 )) , (2.28)

dsdy
R+ Ã—Rd



2
v 2 + 2J02 B G2 (s, y) (G (t âˆ’ s, x âˆ’ y) âˆ’ G(t0 âˆ’ s, x0 âˆ’ y)) Î¸2 (s, y)

where Ï„Î³0 ,...,Î³d ((t, x), (t0 , x0 )) := |t âˆ’ t0 |Î³0 +

Pd

â‰¤ Cn Ï„Î³0 ,...,Î³d ((t, x), (t0 , x0 )) , (2.29)

0 Î³i
i=1 |xi âˆ’ xi | .

The following lemma is useful for verifying Assumption 2.14. Its proof is straightforward
and we leave it to the interested reader.

13

Lemma 2.15. Assumption 2.14 is equivalent to the following statement: Given J0 and
v âˆˆ R, assume that there are d + 1 constants Î³i âˆˆ ]0, 1], i = 0, . . . , d such that for all
n > 1, one can find six finite constants Cn,i < +âˆ, i = 1, . . . , 6, such that for all (t, x) and
(t + h, x + z) âˆˆ Kn := [1/n, n] Ã— [âˆ’n, n]d with h > 0, we have,


(2.30)
v 2 + 2J02 B (G(Â·, â—¦) âˆ’ G(Â· + h, â—¦))2 (t, x) â‰¤ Cn,1 hÎ³0 ,
v

ZZ

ZZ

[t,t+h]Ã—Rd



+ 2J02



2

B (G(Â·, â—¦) âˆ’ G(Â·, â—¦ + z))

(t, x) â‰¤ Cn,3

d
X
i=1

|zi |Î³i ,


dudy v 2 + 2J02 (u, y) G2 (t + h âˆ’ u, x + z âˆ’ y)Î¸2 (u, y) â‰¤ Cn,5 hÎ³0 ,



v

2

2

(2.31)
(2.32)




v 2 + 2J02 B G2 B (G(Â·, â—¦) âˆ’ G(Â· + h, â—¦))2 (t, x) â‰¤ Cn,2 hÎ³0 ,
+ 2J02



2

BG



B (G(Â·, â—¦) âˆ’ G(Â·, â—¦ + z))


2

v 2 + 2J0

dudy
[t,t+h]Ã—Rd

2

(t, x) â‰¤ Cn,4

d
X
i=1

|zi |Î³i ,


B G2 (u, y) G2 (t + h âˆ’ u, x + z âˆ’ y)Î¸2 (u, y) â‰¤ Cn,6 hÎ³0 .

Theorem 2.16. Suppose that the conditions of Theorem 2.13 hold. If, in addition, Assumption 2.14 is also satisfied, then for all compact sets K âŠ† Râˆ—+ Ã— Rd and all p â‰¥ 1, there is a
constant CK,p such that for all (t, x), (t0 , x0 ) âˆˆ K,
||I(t, x) âˆ’ I(t0 , x0 )||p â‰¤ CK,p [Ï„Î³0 ,...,Î³d ((t, x), (s, y))]1/2 ,

and therefore (t, x) 7â†’ I(t, x) belongs to C Î³0 âˆ’, Î³1 âˆ’,..., Î³d âˆ’ Râˆ—+ Ã— Rd a.s. In addition, for
2
2
2
P
0 â‰¤ Î± < 1/2 âˆ’ (1/p) di=0 Î³iâˆ’1 ,
ï£¶p ï£¹
ï£®ï£«
ï£¯ï£¬
ï£¬
Eï£¯
ï£°ï£­

ï£º
|I(t, x) âˆ’ I(s, y)| ï£·
ï£· ï£º
Î± ï£¸ ï£» < +âˆ.
(t,x), (s,y)âˆˆK [Ï„Î³0 ,...,Î³d ((t, x), (s, y))]
sup

(t,x)6=(s,y)

Moreover, if the compact sets Kn in
Assumption 2.14 can be chosen as [0, n] Ã— [âˆ’n, n]d , then

I(t, x) âˆˆ C Î³0 âˆ’, Î³1 âˆ’,..., Î³d âˆ’ R+ Ã— Rd a.s.
2

2

2

Proof. With Propositions 4.4 and 4.5 of [12] replaced by Assumption 2.14 (or equivalently
Lemma 2.15), the proof is identical to part (1) of Theorem 3.1 in [12]. For the range of the
parameter Î±, see [33, Theorem 1.4.1].
2.2.1

Some lemmas and propositions

Following [46], a random field {Z(t, x)} is called elementary if we can write Z(t, x) =
Y 1]a,b] (t)1A (x), where 0 â‰¤ a < b, A âŠ‚ Rd is a rectangle, and Y is an Fa â€“measurable
14

random variable. A simple process is a finite sum of elementary random fields. The set of
d
simple processes generates the
 predictable Ïƒ-field on R+ Ã— R Ã— â„¦, denoted by P. For p â‰¥ 2
d
p
2
and X âˆˆ L R+ Ã— R , L (â„¦) , set
ZZ
2
dsdy ||X (s, y)||2p < +âˆ .
(2.33)
||X||M,p :=
Râˆ—+ Ã—Rd

RR
When p = 2, we write ||X||M instead of ||X||M,2 . As pointed out in [11],
XdW is defined
in [46] for predictable X such that ||X||M < +âˆ. However, the condition of predictability is
not always so easy to check, and as in the case of ordinary Brownian motion [14, Chapter 3],
it is convenient to be able to integrate elements X that are jointly
measurable and adapted.

For this, let Pp denote the closure in L2 R+ Ã— Rd , Lp (â„¦) of simple
RR processes. Clearly,
P2 âŠ‡ Pp âŠ‡ Pq for 2 â‰¤ p â‰¤ q < +âˆ, and according to ItoÌ‚â€™s isometry,
XdW is well-defined
for all elements of P2 . The next two propositions give easily verifiable conditions for checking
that X âˆˆ P2 .
Proposition
2.17. Suppose that for some t > 0 and p âˆˆ [2, +âˆ[ , a random field X =

X (s, y) : (s, y) âˆˆ ]0, t[Ã—Rd has the following properties:

(i) X is adapted and jointly measurable with respect to B R1+d Ã— F;
(ii)

X(Â·, â—¦) 1]0,t[ (Â·) M,p < +âˆ.

Then X(Â·, â—¦) 1]0,t[ (Â·) belongs to P2 .
This proposition is taken from [11, Proposition 2.12], with R there replaced by Rd .
Lemma 2.18. Let G(s, y) be a deterministic
measurable function from Râˆ—+ Ã— Rd to R and

d
âˆ—
let Z = Z (s, y) : (s, y) âˆˆ R+ Ã— R be a process such that

(1) Z is adapted and jointly measurable with respect to B R1+d Ã— F,
(2) ||G 2 (t âˆ’ Â·, x âˆ’ â—¦)Z(Â·, â—¦)||M,2 < +âˆ for all (t, x) âˆˆ Râˆ—+ Ã— Rd .

Then for each (t, x) âˆˆ R+ Ã— Rd , the random field (s, y) âˆˆ [0, t] Ã— Rd 7â†’ G (t âˆ’ s, x âˆ’ y) Z (s, y)
belongs to P2 and so the stochastic convolution
ZZ


G ? Z WÌ‡ (t, x) :=
G (t âˆ’ s, x âˆ’ y) Z (s, y) W (ds, dy)
(2.34)
[0,t]Ã—Rd

is a well-defined Walsh integral and the random field G ? Z WÌ‡ is adapted. Moreover, for all
even integers p â‰¥ 2, and all (t, x) âˆˆ R+ Ã— Rd ,



2
G ? Z WÌ‡ (t, x) â‰¤ zp2 ||G(t âˆ’ Â·, x âˆ’ â—¦)Z(Â·, â—¦)||2M,p .
p

15

This lemma is taken from [11, Lemma 2.14], again with R there replaced by Rd .
Proposition 2.19. Suppose
 that for some even integer p âˆˆ [2, +âˆ[ , a random field Y =
d
âˆ—
Y (t, x) : (t, x) âˆˆ R+ Ã— R has the following properties
(i) Y is adapted and jointly measurable;

(ii) for all (t, x) âˆˆ Râˆ—+ Ã— Rd , ||Y (Â·, â—¦)Î¸(Â·, â—¦)G(t âˆ’ Â·, x âˆ’ â—¦)||2M,p < +âˆ.
Then for each (t, x) âˆˆ Râˆ—+ Ã— Rd , Y (Â·, â—¦)Î¸(Â·, â—¦)G(t âˆ’ Â·, x âˆ’ â—¦) âˆˆ P2 , the following Walsh integral
ZZ
w(t, x) =
Y (s, y) Î¸(s, y)G (t âˆ’ s, x âˆ’ y) W (ds, dy)
]0,t[Ã—Rd

is well defined and the resulting random field w is adapted. Moreover, w is Lp (â„¦))-continuous
over Râˆ—+ Ã— Rd under either of the following two conditions:
e (Heat type):
( H)

e
( H-i)
G satisfies Assumptions 2.6 and 2.7.
e
( H-ii)
sup(t,x)âˆˆK ||Y (t, x)||p < +âˆ for all compact sets K âŠ† Râˆ—+ Ã— Rd , which is true, in
particular, if Y is Lp (â„¦)-continuous.

f (Wave type) G satisfies Assumptions 2.5.
( W)

Proof. Fix (t, x) âˆˆ Râˆ—+ Ã— Rd . By Assumption (iii) and the fact that G(t, x) is Borel
measurable and deterministic, the random field X = X (s, y) : (s, y) âˆˆ ]0, t[Ã—Rd with
X (s, y) := Y (s, y) Î¸ (s, y) G (t âˆ’ s, x âˆ’ y) satisfies all conditions of Proposition 2.17. This
implies that Y (Â·, â—¦)Î¸ (Â·, â—¦) G(t âˆ’ Â·, x âˆ’ â—¦) âˆˆ Pp . Hence w(t, x) is a well-defined Walsh integral
and the resulting random field is adapted to the filtration {Fs }sâ‰¥0 .
e the proof is identical to that of [11, Proposition 2.15], except that
Under condition (H),
appeals there to Proposition 2.18 are replaced by appeals to Assumption 2.6.
f For two points (t, x), (t0 , x0 ) âˆˆ R+ Ã— Rd , recall (tâˆ— , xâˆ— ) and (tÌ‚, xÌ‚)
Assume condition (W).
are defined in (2.5). Choose Î² âˆˆ ]0, 1[ , Ï„ > 0 and Î± > 0 according to Assumption 2.5. Fix
(t, x) âˆˆ Râˆ—+ Ã— Rd . Let B := Bt,x,Î²,Ï„,Î± be the set defined in (2.3) and C be the constant used
in Assumption 2.5. Assume that (t0 , x0 ) âˆˆ B. By Lemma 2.18, we have that
p

||w(t, x) âˆ’ w (t0 , x0 )||p
Z tâˆ— Z
pâˆ’1 p
â‰¤ 2 zp
ds

Rd

0

+ 2pâˆ’1 zpp

Z tÌ‚
tâˆ—

ds

2
dy ||Y (s, y)||2p Î¸(s, y)2 (G(t âˆ’ s, x âˆ’ y) âˆ’ G(t0 âˆ’ s, x0 âˆ’ y))

Z

Rd

dy ||Y (s, y)||2p Î¸(s, y)2 G2

p/2

â‰¤ 2pâˆ’1 zpp (L1 (t, t0 , x, x0 ))

tÌ‚ âˆ’ s, xÌ‚ âˆ’ y
p/2

+ 2pâˆ’1 zpp (L2 (t, t0 , x, x0 ))
16

.

!p/2


p/2

(2.35)

We first consider L1 . By Assumption 2.5,
2

(G (t âˆ’ s, x âˆ’ y) âˆ’ G (t0 âˆ’ s, x0 âˆ’ y)) â‰¤ 4C 2 G2 (t + 1 âˆ’ s, x âˆ’ y) ,
and the left-hand side converges pointwise to 0 for almost all (t, x). Further,
ZZ
dsdy 4C 2 G2 (t + 1 âˆ’ s, x âˆ’ y) ||Y (s, y)||2p Î¸(s, y)2
[0,tâˆ— ]Ã—Rd

â‰¤4C 2 ||Y (Â·, â—¦)Î¸(Â·, â—¦)G(t + 1 âˆ’ Â·, x âˆ’ â—¦)||2M,p ,

which is finite by (ii). Hence, by the dominated convergence theorem,
lim

(t0 ,x0 )â†’(t,x)

L1 (t, t0 , x, x0 ) = 0.

Similarly, for L2 , by Assumption 2.5,


G2 tÌ‚ âˆ’ s, xÌ‚ âˆ’ y â‰¤ C 2 G2 (t + 1 âˆ’ s, x âˆ’ y) .

By the monotone convergence theorem, lim(t0 ,x0 )â†’(t,x) L2 (t, t0 , x, x0 ) = 0, because
ZZ
dsdy C 2 G2 (t + 1 âˆ’ s, x âˆ’ y) ||Y (s, y)||2p Î¸(s, y)2
d
[tâˆ— ,tÌ‚]Ã—R
â‰¤C 2 ||Y (Â·, â—¦)Î¸(Â·, â—¦)G(t + 1 âˆ’ Â·, x âˆ’ â—¦)||2M,p
f
is finite by (ii). This completes the proof under condition (W).

We need a lemma which transforms the stochastic integral equation (2.1) into integral
inequalities for its moments. The proof is similar to that of [11, Lemma 2.19].
Lemma 2.20. Suppose that f (t, x) is a deterministic function and Ï satisfies the growth
condition (2.19). If the random fields w and v satisfy, for all (t, x) âˆˆ R+ Ã— Rd ,

h
i
w (t, x) = f (t, x) + G C Ï(v)WÌ‡ (t, x) ,
in which the second term is defined by
Z tZ

h
i
G (t âˆ’ s, x âˆ’ y) Î¸ (s, y) Ï (v (s, y)) W (ds, dy) ,
G C Ï(v)WÌ‡ (t, x) :=
0

Rd

where we assume that the Walsh integral is well defined, then for all even integers p â‰¥ 2 and
(t, x) âˆˆ R+ Ã— Rd ,

h
i
2
G C Ï(v)WÌ‡ (t, x) â‰¤ zp2 ||G (t âˆ’ Â·, x âˆ’ â—¦) Ï(v(Â·, â—¦)) Î¸ (Â·, â—¦)||2M,p
p


1  2
Ï‚ + ||v||2p B Lb0 (t, x) ,
â‰¤
bp
where bp = 1 if p = 2 and bp = 2 otherwise. In particular,



||w (t, x)||2p â‰¤ bp f 2 (t, x) + Ï‚ 2 + ||v||2p B Lb0 (t, x) .
17

2.2.2

Proof of Theorem 2.13

The proof follows the same six steps as in the proof of [11, Theorem 2.4] with the following
replacements:
Proposition 2.2 of [11] by Assumptions 2.11, 2.12;
Lemma 2.14, ibid., by Lemma 2.18;
Proposition 2.15, ibid., by Proposition 2.19;
Lemma 2.19, ibid., by Lemma 2.20;
Lemma 2.21, ibid., by Assumption 2.4.
Under Condition (H), after making the following further replacements, the proof will be
identical to [11, Theorem 2.4]:
Proposition 2.16, ibid., by Assumption 2.7 and Condition (H)â€“(a);
Proposition 2.18, ibid., by Assumption 2.6 and Condition (H)â€“(a);
Lemma 2.20, ibid., by Assumption 2.8 and Condition (H)â€“(b).
The only care that we should take is that under Condition (W), i.e., Assumption 2.5, the
proof should be also modified in certain places. In the following, we will highlight these
changes.
Recall that in Step 1, we define u0 (t, x) = J0 (t, x) and show by the above (the first set
of) replacements that
ZZ
G(t âˆ’ s, x âˆ’ y) Î¸ (s, y) Ï (u0 (s, y)) W (ds, dy)
I1 (t, x) =
[0,t]Ã—Rd


is a well defined Walsh integral and the random field I1 (t, x) : (t, x) âˆˆ R+ Ã— Rd is adapted
and jointly measurable. The only difference is that the continuity of (t, x) 7â†’ I1 (t, x) from
f of Proposition 2.19.
Râˆ—+ Ã— Rd into Lp (â„¦) is guaranteed by part (W)
Step 2 gives the Picard iteration, where we assume that for all k â‰¤ n and (t, x) âˆˆ Râˆ—+ Ã—Rd ,
the Walsh integral
ZZ
Ik (t, x) =
G (t âˆ’ s, x âˆ’ y) Î¸ (s, y) Ï (ukâˆ’1 (s, y)) W (ds, dy)
[0,t]Ã—Rd

is well defined such that
(1) uk := J0 + Ik is adapted.
(2) The function (t, x) 7â†’ Ik (t, x) from Râˆ—+ Ã— Rd into Lp (â„¦) is continuous.
P
2
2
(3) E [u2k (t, x)]=J02 (t, x) + kâˆ’1
i=0 ([Ï‚ +J0 ] B Li (t, x; Â·, â—¦)) (t, x) for the quasi-linear case and
is bounded from above and below (if Ï satisfies (2.20) additionally):
J02 (t, x) +

kâˆ’1
X
 2


Ï‚ +J02 B Li (t, x; Â·, â—¦) (t, x)
i=0

18

â‰¤ ||uk (t, x)||22 â‰¤ J02 (t, x) +
Pkâˆ’1 

(4) ||uk (t, x)||2p â‰¤ bp J02 (t, x) +

i=0

kâˆ’1
X

i=0



Ï‚ 2 +J02 B Li (t, x; Â·, â—¦) (t, x) .


(Ï‚ 2 +bp J02 ) B Lbi (t, x; Â·, â—¦) (t, x).

To prove parts (3) and (4) for the case k = n + 1, we need to apply Lemma 2.20 and (2.11)
in Lemma 2.10 to properly deal with the order of the Î¸-weighted convolutions. Again, the
f of Proposition 2.19.
Lp (â„¦)-continuity of (t, x) 7â†’ In+1 (t, x) is proved by part (W)
Similarly, in Step 3, we claim that for all (t, x) âˆˆ Râˆ—+ Ã— Rd , the series {In (t, x) :
n âˆˆ N}, with I0 (t, x) := J0 (t, x), is a Cauchy sequence in Lp (â„¦). Define Fn (t, x) =
||In+1 (t, x) âˆ’ In (t, x)||2p . For n â‰¥ 1, by Lemma 2.18,


Fn (t, x) â‰¤ Fnâˆ’1 B Le0 (t, x) ,


where Le0 (t, x) := L0 t, x; zp max LipÏ , ap,Ï‚ LÏ . Then apply this relation recursively using
(2.9) in Lemma 2.10 to obtain that





 


Ï‚ 2 +J02 B Le0 B Le0 B Â· Â· Â· B Le0 (t, x) ,
Fn (t, x) â‰¤ Fnâˆ’1 B Le0 (t, x) â‰¤ Â· Â· Â· â‰¤ Â· Â· Â·
where the r.h.s. of the inequality has n + 1 convolutions. We now apply (2.9) in Lemma
2.10. then Assumption 2.12 to obtain






2
2
2
2
e
e
Fn (t, x) â‰¤ Ï‚ +J0 B Ln (t, x; Â·, â—¦) (t, x) â‰¤ Ï‚ +J0 B L0 (t, x) Bn (t),

where the kernel functions Len (t, x; s, y) are defined by the same parameter as Le0 (t, x).
Towards the end of Step 4, we need to apply Lebesgueâ€™s dominated convergence theorem.
To check the integrability of the integrand, we use (2.17) and then Lemma 2.10.
e again we need to apply (2.10)
In Step 5, when we convolve an extra kernel function K,
in Lemma 2.10 to deal with the order of the Î¸â€“weighted convolution.
With these replacements and changes, Theorem 2.13 is also proved under Condition (W).


2.3

Application to the stochastic heat equation with distributionvalued initial data

We apply Theorem 2.13 to study the stochastic heat equation

(
âˆ‚
Î½ âˆ‚2
âˆ’ 2 âˆ‚x2 u(t, x) = Ï(u(t, x)) Î¸(t, x) WÌ‡ (t, x), x âˆˆ R, t âˆˆ Râˆ—+ ,
âˆ‚t
u(0, Â·) = Âµ(Â·) .

19

(2.36)

Let GÎ½ (t, x) be the heat kernel, i.e.,
 2
1
x
GÎ½ (t, x) = âˆš
exp âˆ’
,
4t
4Ï€Î½t

for t > 0 and x âˆˆ R.

(2.37)

We will focus on this equation with general initial data, and we will study how certain
properties of Î¸(t, x) function affect the admissible initial data â€“ the initial data starting from
which the stochastic heat equation (2.36) admits a random field solution. Recall that [11,
Proposition 2.11] shows that if Î¸(t, x) â‰¡ 1, then the initial data cannot go beyond measures.
As for the properties of Î¸(t, x), we will not pursue the full generality here. Instead, we
only consider certain particular Î¸(t, x) to show the balance between certain properties of
Î¸(t, x) and the set of the admissible initial data. For r â‰¥ 0, define
)
(
\
|Î¸(t, x)|
Îr := Î¸ : R+ Ã— R 7â†’ R : sup
<
+âˆ
,
and
Î
:=
În .
âˆ
r
(t,x)âˆˆRâˆ—+ Ã—R t âˆ§ 1
nâˆˆN
Clearly, if 0 â‰¤ m â‰¤ n, then Îm âŠ‡ În . Here are some simple examples: tk âˆ§ 1 âˆˆ Îk for all
k â‰¥ 0; exp (âˆ’1/t) âˆˆ Î+âˆ .
Let Ccâˆ (R) be the space of the C âˆ -functions with compact support. Let D0 (R) be the
space of distributions â€” the dual space of Ccâˆ (R). Let Âµ be a locally finite measure on R and
let Âµ = Âµ+ âˆ’ Âµâˆ’ be its Jordan decomposition into two non-negative measures with disjoint
supports. Denote |Âµ| = Âµ+ + Âµâˆ’ .
Definition 2.21. Let MH (R) be the set of signed Borel measures Âµ on R such that for all
t > 0 and x âˆˆ R, (|Âµ| âˆ— GÎ½ (t, Â·)) (x) < +âˆ. For k âˆˆ N, define
o
n
[
(k)
0
Dk0 (R) ,
(R) =
Dk0 (R) = Âµ âˆˆ D0 (R) : âˆƒÂµ0 âˆˆ MH (R) , s.t. Âµ = Âµ0 , and D+âˆ
kâˆˆN

(k)

where Âµ0 denotes the k-th distributional derivative.
Theorem 2.22. Suppose that Ï is Lipschitz continuous. If Î¸(t, x) âˆˆ Îr for some 0 â‰¤ r â‰¤
+âˆ, then (2.36) has a solution {u(t, x) : t > 0, x âˆˆ R} in the sense of Definition 2.1 for
any initial data Âµ âˆˆ Dk0 (R) with k âˆˆ N and 0 â‰¤ k < 2r + 1/2. Moreover, the solution u(t, x)
is unique (in the sense of versions) and is Lp (â„¦) -continuous over Râˆ—+ Ã— R for all p â‰¥ 2. In
addition, the estimates of Theorem 2.13 apply.
The proof of this theorem is given at the end of this section.
Example 2.23. If Î¸(t, x) â‰¡ 1, then Î¸ âˆˆ Îr if and only if r = 0. So, by Theorem 2.22, the
admissible initial data are D00 (R), which recovers the condition (|Âµ| âˆ— GÎ½ (t, Â·)) (x) < âˆ for
all t > 0 and x âˆˆ R in [11].
Example 2.24 (Derivatives of the Dirac delta functions). If Î¸(t, x) = tr âˆ§ 1, then the initial
(k)
data can be Î´0 with 0 â‰¤ k < 2r + 1/2. This is consistent with [11, Proposition 2.11]. If
Î¸(t, x) = exp (âˆ’1/t), then all derivatives of Î´0 are admissible initial data.
20

Example 2.25 (Schwartz distribution-valued initial data and beyond). If we choose Î¸(t, x) âˆˆ
Î+âˆ , for example Î¸(t, x) = exp (âˆ’1/t), then the initial data can be any Schwartz distribution.
0
(R) can go beyond Schwartz distributions. Here
Actually, the admissible initial data D+âˆ
(k)
are some simple examples: Âµ(dx) = Âµ0 (dx) for any k âˆˆ N, where Âµ0 (dx) = e|x| dx.
Let âˆ‚yn and âˆ‚tn be the n-th partial derivatives with respect to y and t, respectively. In
particular,
âˆ‚yk [GÎ½ (t, x âˆ’ y)] = (âˆ’1)k

âˆ‚k
GÎ½ (t, z)
= (âˆ’1)k âˆ‚xk GÎ½ (t, x âˆ’ y) .
âˆ‚z k
z=xâˆ’y

As a special case of a standard result (see, e.g., [31, Theorem 1, Chapter 9, p.241] or [27,
(15), p. 15]), for all t â‰¥ 0 and n âˆˆ N, there are two constants Cn and Î½n depending only1 on
n and Î½ such that
Cn
âˆ‚yn GÎ½ (t, x âˆ’ y) â‰¤ n/2 GÎ½n (t, x âˆ’ y) , for all t â‰¥ 0, and x, y âˆˆ R.
(2.38)
t
Remark 2.26. For the heat kernel function, the bound in (2.38) can be improved. Let
Hen (x; t) be the Hermite polynomials:
nâˆ’2k

bn/2c 
X n
x
, for all t > 0 and x âˆˆ R,
Hen (x ; t) :=
(2k âˆ’ 1)!! âˆ’ âˆš
2k
t
k=0
where bn/2c is the largest integer not bigger than n/2 and n!! is the double factorial (see
[38]). Then âˆ‚yn [GÎ½ (t, x âˆ’ y)] = (Î½t)âˆ’n/2 GÎ½ (t, x âˆ’ y) Hen (x âˆ’ y; Î½t); see Theorem 9.3.3 of
[34]. Then one can remove the Hermite polynomials by increasing the parameter Î½ in the
heat kernel function to obtain the upper bound of the form (2.38).
Lemma 2.27. Suppose that Âµ âˆˆ MH (R), and n, m, a, b âˆˆ N. Then for all t > 0 and x âˆˆ R,
Z
Z
a b
n m
âˆ‚t âˆ‚x Âµ(dy) âˆ‚t âˆ‚x GÎ½ (t, x âˆ’ y) =
Âµ(dy) âˆ‚tn+a âˆ‚xm+b GÎ½ (t, x âˆ’ y) .
R

R

Î½/2 âˆ‚x2 GÎ½ .

Note that âˆ‚t GÎ½ =
The proof consists of using standard results (e.g., [3,
Theorem 16.8]) on permuting integrals and differential signs. Now define

J0 (t, x) := (âˆ’1)k Âµ0 âˆ— âˆ‚yk [G1 (Î½t, Â·)] (x), for all (t, x) âˆˆ Râˆ—+ Ã— R ,
(2.39)

which, by (2.38), can be bounded by,

|J0 (t, x)| â‰¤ Ck tâˆ’k/2 (|Âµ0 | âˆ— GÎ½k (t, Â·)) (x) ,

(2.40)

for some positive constants Ck and Î½k . As a direct consequence
 of Lemma 2.27, for all
0
âˆ
âˆ—
Âµ âˆˆ Dk (R), J0 (t, x) defined in (2.39) belongs to C R+ Ã— R , which is the smoothing
property of the heat kernel.
The following lemma is a standard result (see [30] and also [10, Proposition 2.6.14]).
1
There is no dependence on a finite horizon T > 0 because the coefficients of our parabolic equation are
constant, while in both [27] and [31] they are time-dependent. See Remark 2.26 for a brief proof of this fact.

21

Lemma 2.28. Suppose that Âµ âˆˆ Dk0 (R), k âˆˆ N. Let Âµ0 âˆˆ MH (R) be the signed Borel
(k)
measure associated to Âµ such that Âµ = Âµ0 . Then the function J0 (t, x) defined in (2.39)
solves

(
âˆ‚
Î½ âˆ‚2
âˆ’
u(t, x) = 0, x âˆˆ R, t âˆˆ Râˆ—+ ,
âˆ‚t
2 âˆ‚x2
(2.41)
u(0, Â·) = Âµ(Â·) ,
and limtâ†’0+ hÏˆ, J0 (t, Â·)i = hÏˆ, Âµi for all Ïˆ âˆˆ Ccâˆ (R).
Proposition 2.29. Suppose that Î¸(t, x) âˆˆ Îr and Âµ âˆˆ Dk0 (R) with 0 â‰¤ k < 2r + 1/2. Then
for all v > 0 and all compact sets K âŠ† Râˆ—+ Ã— R,


 2
sup
v + J02 B G2Î½ (t, x) < +âˆ.
(t,x)âˆˆK

(k)

Proof. Let Âµ0 âˆˆ MH (R) be such that Âµ = Âµ0 . Then J0 (t, x) given in (2.39) is a weak
solution to the homogeneous equation (see also [10, Lemma 2.6.14]). We assume first that
v = 0. Since for some constant C, |Î¸(t, x)| â‰¤ C (1 âˆ§ tr ) â‰¤ Ctr , it suffices to prove that, for
all compact sets K âŠ† Râˆ—+ Ã— R,
ZZ
dsdy J02 (s, y) s2r G2Î½ (t âˆ’ s, x âˆ’ y) .
sup f (t, x) < +âˆ, where f (t, x) :=
(t,x)âˆˆK

[0,t]Ã—R

Without loss of generality, we assume from now that the measure Âµ0 is non-negative. We
will use the bound on J0 (t, x) in (2.40) and denote Î¾ := Î½k . Because Î¾ > Î½ (see Remark
2.26),
GÎ½ (t âˆ’ s, x âˆ’ y)
sup
< +âˆ .
(s,y)âˆˆ[0,t]Ã—R GÎ¾ (t âˆ’ s, x âˆ’ y)
Hence, for some constant C > 0,
ZZ
dsdy s2râˆ’k (Âµ0 âˆ— GÎ¾ (s, Â·))2 (y) G2Î¾ (t âˆ’ s, x âˆ’ y).
|f (t, x)| â‰¤ C
[0,t]Ã—R

Then write (Âµ0 âˆ— GÎ¾ (s, Â·))2 (y) in the form of double integral and use Lemma A.4:
Z t
ZZ
C s2râˆ’k
|f (t, x)| â‰¤
ds p
Âµ0 (dz1 )Âµ0 (dz2 ) G2Î¾ (s, z1 âˆ’ z2 )
4Ï€Î¾(t âˆ’ s) R2
0
Z
Ã— dy G Î¾ (s, y âˆ’ zÌ„) G Î¾ (t âˆ’ s, x âˆ’ y) ,
R

2

2

where zÌ„ = (z1 + z2 )/2. By the semigroup property of the heat kernel function,
Z t
ZZ
C s2râˆ’k
|f (t, x)| â‰¤
ds p
Âµ0 (dz1 )Âµ0 (dz2 ) G2Î¾ (s, z1 âˆ’ z2 ) G Î¾ (t, x âˆ’ zÌ„).
2
4Ï€Î¾(t âˆ’ s) R2
0
22

Apply Lemma A.5 to G2Î¾ (s, z1 âˆ’ z2 ) G Î¾ (t, x âˆ’ zÌ„) to see that
2

âˆš
C s2râˆ’kâˆ’1/2 t
ds p
.
|f (t, x)| â‰¤ (Âµ0 âˆ— G2Î¾ (t, Â·)) (x)
Ï€Î¾(t âˆ’ s)
0
2

Z t

(2.42)

The integration over s is finite since 2r âˆ’ k âˆ’ 1/2 > âˆ’1. By the smoothing effect of the heat
kernel, for any arbitrary compact set K âŠ† Râˆ—+ Ã— R, sup(t,x)âˆˆK (Âµ0 âˆ— G2Î¾ (t, Â·))2 (x) is finite.
This proves the proposition with v = 0. As for the contribution of v, we simply replace
Âµ0 (dx) by v dx in (2.42). This completes the proof of Proposition 2.29.
Proof of Theorem 2.22. We only need to verify that Conditions (G) and (H) of Theorem
2.13 are satisfied. Fix r âˆˆ [0, +âˆ] and Î¸(t, x) âˆˆ Îr . Since Î¸ is uniformly bounded and d = 1,
Assumption 2.3 is satisfied. Assumptions 2.11 and 2.12 are verified by [11, Proposition
2.2] with Î» = C LÏ . Assumption 2.4 is true due to Proposition 2.29, where the hypothesis
0 â‰¤ k < 2r + 1/2 is used. Therefore, all conditions in (G) are satisfied. Both Assumptions
2.6 and 2.7 are satisfied due to Propositions 2.18 and 2.16 of [11], respectively. Assumption
2.8 is true by Lemma 2.20, ibid. Therefore, all conditions in (H) are satisfied. This completes
the proof of Theorem 2.22.

3

Stochastic wave equation

We now turn to the study of the stochastic wave equation (1.6). Recall the formulas for
J0 (t, x) and for the fundamental solution GÎº (t, x) given in (1.7).

3.1

Existence, uniqueness, moments and regularity

Define a kernel function
q

ï£±
Î»2 ((Îºt)2 âˆ’x2 )
ï£² Î»2 I
if âˆ’Îºt â‰¤ x â‰¤ Îºt ,
0
2Îº
K (t, x; Îº, Î») := 4
ï£³
0
otherwise ,

(3.1)

with two parameters Îº > 0 and Î» > 0, where In (Â·) is the modified Bessel function of the first
kind of order n, or simply the hyperbolic Bessel function ([38, 10.25.2, on p. 249]):
In (x) :=

âˆ
 x n X

2

k

(x2 /4)
.
k! Î“(n + k + 1)
k=0

See [32, 47] for its relation with the wave equation. Define
 p

H (t; Îº, Î») := (1 ? K) (t, x) = cosh |Î»| Îº/2 t âˆ’ 1 ,
23

(3.2)

(3.3)

where the second equality is proved in Lemma A.2 below. The following bound on I0 (x) will
be useful and convenient for the later applications of the moment formula:
I0 (z) â‰¤ cosh(z) â‰¤ e|z| , for all z âˆˆ R,
(3.4)
RÏ€
which can be seen from the formula I0 (z) = Ï€1 0 dÎ¸ cosh(z cos(Î¸)) (see [38, (10.32.1)]). We
use the same conventions as (2.14) regarding to the parameter Î». For example, K(t, x) :=
b p (t, x) := K (t, x; Îº, ap,Ï‚ zp LÏ ). Define two functions:
K (t, x; Îº, Î») and K


|x|
TÎº (t, x) := t âˆ’
1{|x|â‰¤2Îºt} ,
(3.5)
2Îº
ZZ
Îº
Î˜Îº (t, x, y) :=
dsdz GÎº (t âˆ’ s, x âˆ’ z)GÎº (t âˆ’ s, y âˆ’ z) = TÎº2 (t, x âˆ’ y) ,
(3.6)
4
R+ Ã—R
where the second equality is proved in Lemma 3.8. This is the quantity Î˜ (t, x, y) in (2.2).
Let M (R) be the set of locally finite (signed) Borel measures over R.

Theorem 3.1. Suppose that g âˆˆ L2loc (R), Âµ âˆˆ M (R) and Ï is Lipschitz continuous with
|Ï(u)|2 â‰¤ L2Ï (Ï‚ 2 +u2 ). Define K, H, TÎº , etc., as above. Then the stochastic integral equation
(1.8) has a random field solution, in the sense of Definition 2.1: u(t, x) = J0 (t, x) + I(t, x)
for t > 0 and x âˆˆ R. Moreover,
(1) u(t, x) is unique (in the sense of versions);
(2) (t, x) 7â†’ I(t, x) is Lp (â„¦)-continuous for all integers p â‰¥ 2;
(3) For all even integers p â‰¥ 2 and all t > 0, x, y âˆˆ R,
( 2

2
K
(t,x) + Ï‚ 2 H(t)
if p = 2,
J
(t,
x)
+
J
?
0
0
||u(t, x)||2p â‰¤
(3.7)
2
2
2
bp (t) if p > 2,
b p (t, x) + Ï‚ H
2J0 (t, x) + 2J0 ? K


Îº L2Ï Ï‚ 2 2
L2Ï
x+y
TÎº (t, x âˆ’ y) +
(f ? GÎº ) T,
, (3.8)
E [u(t, x)u(t, y)] â‰¤ J0 (t, x)J0 (t, y) +
4
2
2
where T = TÎº (t, x âˆ’ y) and f (s, z) denotes the r.h.s. of (3.7) for p = 2;
(4) If Ï satisfies (2.20), then for all t > 0, x, y âˆˆ R,

||u(t, x)||22 â‰¥ J02 (t, x) + J02 ? K (t, x) + Ï‚ 2 H(t),
(3.9)


2 2
2
Îº lÏ Ï‚
lÏ
x+y
E [u(t, x)u(t, y)] â‰¥ J0 (t, x)J0 (t, y) +
TÎº2 (t, x âˆ’ y) + (f ? GÎº ) T,
, (3.10)
4
2
2
where T = TÎº (t, x âˆ’ y) and f (s, z) denotes the r.h.s. of (3.9);
(5) In particular, if |Ï(u)|2 = Î»2 (Ï‚ 2 +u2 ), then for all t > 0, x, y âˆˆ R,

||u(t, x)||22 = J02 (t, x) + J02 ? K (t, x) + Ï‚ 2 H(t),
(3.11)


Î»2
x+y
ÎºÎ»2 Ï‚ 2 2
TÎº (t, x âˆ’ y) +
(f ? GÎº ) T,
, (3.12)
E [u(t, x)u(t, y)] = J0 (t, x)J0 (t, y) +
4
2
2
where T = TÎº (t, x âˆ’ y) and f (s, z) = ||u(s, z)||22 is defined in (3.11).
24

The proof of this theorem is given at the end of Section 3.2.
Corollary 3.2 (Constant initial data). Suppose that Ï2 (x) = Î»2 (Ï‚ 2 +x2 ) with Î» 6= 0. Let
H(t) be defined as above. If g(x) â‰¡ w and Âµ(dx) = w
e dx with w, w
e âˆˆ R, then:

(1) For all t â‰¥ 0 and x âˆˆ R,

||u(t, x)||22 = w2 +
In particular,

âˆš


âˆš

2
4Îº
w
e
2
2Îºww
e
Îº|Î»|t
2
2
âˆš
w +Ï‚ + 2
H(t) +
sinh
.
Î»
|Î»|
2

||u(t, x)||22 =

ï£±
2
ï£´
ï£²w (H (t) + 1)
2

4Îºw
e
ï£´
ï£³
H(t)
2
Î»

if Ï‚ = w
e = 0,

if Ï‚ = w = 0.

(2) For all t â‰¥ 0 and x, y âˆˆ R, set T = TÎº (t, x âˆ’ y). Then
e (t âˆ’ T ) (2w + Îºw(t
e + T ))
E [u(t, x)u(t, y)] = w2 + Îºw
âˆš

âˆš


2
4Îº
w
e
2Îºww
e
Îº|Î»|
2
2
2
âˆš T .
+ w +Ï‚ + 2
sinh
H (T ) +
Î»
|Î»|
2

In particular,

E [u(t, x)u(t, y)] =

ï£±
2
ï£´
ï£²w (H (T ) + 1)


4Îºw
e
ï£´
2 2
2
2
ï£³
H
(T
)
+
Îº
w
e
t
âˆ’
T
Î»2
2

if Ï‚ = w
e = 0,

if Ï‚ = w = 0.

Proof. (1) In this case, J0 (t, x) = w + Îºwt.
e The formula for ||u(t, x)||22 follows from the
moment formula (3.11) and the integrals in Lemmas A.2 and A.1.
(2) The formulas follow from (3.12) and (1), and the integrals in (3.6) and Lemma A.1.
Corollary 3.3 (Dirac delta initial velocity). Suppose that Ï2 (x) = Î»2 (Ï‚ 2 +x2 ) with Î» 6= 0.
If g â‰¡ 0 and Âµ = Î´0 , then for all t â‰¥ 0 and x, y âˆˆ R,


x+y
1
E [u(t, x)u (t, y)] = 2 K TÎº (t, x âˆ’ y) ,
+ Ï‚ 2 H (TÎº (t, x âˆ’ y)) .
Î»
2
In particular, ||u(t, x)||22 = Î»12 K(t, x) + Ï‚ 2 H(t).
Proof. In this case, J0 (t, x) = GÎº (t, x) and so Î»2 J02 (t, x) = L0 (t, x). Set T = TÎº (t, x âˆ’ y) and
xÌ„ = (x + y)/2. By (3.11) and Proposition 3.6, ||u(t, x)||22 = Î»12 K(t, x) + Ï‚ 2 H(t). By (3.12)
and (3.16),
1
E [u(t, x)u (t, y)] = GÎº (T, xÌ„) + Î»2 Ï‚ 2 Î˜Îº (t, x, y)
2
25

Î»2
+
2

Z T

ds

0

Z

dz

R




1
2
K(s, z) + Ï‚ H(s) GÎº (T âˆ’ s, xÌ„ âˆ’ z) .
Î»2

By (3.15), the double integral with Î»2 /2 in the above formula equals
1
1
K (T, xÌ„) âˆ’ GÎº (T, xÌ„) + I,
2
Î»
2
where

Î»2 Ï‚ 2
I=
2

Z T
0

ds H(s)

Z

R

dz GÎº (T âˆ’ s, xÌ„ âˆ’ z) .

Now let us evaluate the integral I. The dzâ€“integral is equal to Îº(T âˆ’s). By (3.3) and Lemma
A.1,
Z
Î»2 Ï‚ 2 T
ÎºÎ»2 Ï‚ 2 2
I=
ds H(s) Îº (T âˆ’ s) = Ï‚ 2 H (T ) âˆ’
T = Ï‚ 2 H (T ) âˆ’ Î»2 Ï‚ 2 Î˜Îº (t, x, y) .
2
4
0
Finally, the corollary is proved by combining these terms.
Example 3.4. Let g(x) = |x|âˆ’1/4 and Âµ â‰¡ 0. Clearly, g âˆˆ L2loc (R) and
1
J02 (t, x) =

4



1
1
+
|x + Îºt|1/4 |x âˆ’ Îºt|1/4

2

.

The function J02 (t, x) equals +âˆ on the characteristic lines x = Â±Îºt that originate at
(0, 0), where the singularity of g occurs. Nevertheless, the stochastic integral part I(t, x)
is well defined for all (t, x) âˆˆ Râˆ—+ Ã— R and the random field solution u(t, x) in the sense of
Definition 2.1 does exist according to Theorem 3.1. We note that the argument for the heat
equation in Theorem 2.13, which is based on Condition (H), cannot be used here because
of the singularity of J0 (t, x) at certain points. However, the wave kernel function satisfies
Condition (W), which is not satisfied by the heat kernel.
t
tc = (2Îº)âˆ’1
x
âˆ’3

âˆ’2

âˆ’1

0

1

2

3


P
Figure 1: When g(x) = nâˆˆN 2âˆ’n |x âˆ’ n|âˆ’1/2 + |x + n|âˆ’1/2 and Âµ â‰¡ 0, the random field
solution u(t, x) is only defined in the unshaded regions and in particular not for t > tc =
(2Îº)âˆ’1 .

26

Example 3.5. Let g(x) = |x|âˆ’1/2 and Âµ â‰¡ 0. Clearly, g 6âˆˆ L2loc (R). So Theorem 3.1 does
not apply. In this case, the solution u(t, x) is well defined outside of the triangle Îº t â‰¥ |x|.
But because

2
1
1
1
2
J0 (t, x) =
+
,
4 |x + Îºt|1/2 |x âˆ’ Îºt|1/2

and this function is not locally integrable over domains that intersect the characteristic lines
x = Â±Îºt (see Assumption 2.4), the random field solution exists only in the two â€œtrianglesâ€
Îº t â‰¤ |x|. Another example is shown in Figure 1.

3.2

Some lemmas and propositions for the existence theorem

Define the backward space-time cone:
Î›(t, x) = {(s, y) âˆˆ R+ Ã— R : 0 â‰¤ s â‰¤ t, |y âˆ’ x| â‰¤ Îº(t âˆ’ s)}
and the wave kernel function can be equivalently written as GÎº (t âˆ’ s, x âˆ’ y) = 12 1Î›(t,x) (s, y).
The change of variables u = Îºs âˆ’ y, w = Îºs + y will play an important role: see Figure 2.
w

Îºs

âˆ’

y

s
Îºs

u

=

=
+

t

âˆ’

x

+

Îºt

y

x
+

x
t
2 âˆ’ 2Îº

Îºt

III

I

II
y

x

Îº
x
2 âˆ’ 2t

Îº
x
2 + 2t

x + Îºt

Îºt

x âˆ’ Îºt

t
x
2 + 2Îº

âˆ’

x

âˆ’

  
w
Îº
=
Îº
u

w = âˆ’u

x
âˆ’

 
s
1
âˆ’1
y

Îºt

dwdu = 2Îºdsdy

Figure 2: Change variables for the case where |x| â‰¤ Îºt.
For all n âˆˆ Nâˆ— and (t, x) âˆˆ Râˆ—+ Ã— R, recall that L0 (t, x; Î») = Î»2 G2Îº (t, x) and Ln (t, x; Î») =
(L0 ? Â· Â· Â· ? L0 )(t, x), where there are n + 1 convolutions of L0 (Â·, â—¦; Î»).
Proposition 3.6. For all n âˆˆ N, and (t, x) âˆˆ Râˆ—+ Ã— R,
Ln (t, x) =

( Î»2n+2 (Îºt)2 âˆ’x2 n
(
)
23n+2 (n!)2 Îºn

0

27

if âˆ’Îºt â‰¤ x â‰¤ Îºt,
otherwise,

(3.13)

K(t, x) =

âˆ
X
n=0

Ln (t, x), and

(K ? L0 ) (t, x) = K(t, x) âˆ’ L0 (t, x) .

(3.14)
(3.15)

Moreover, there are non-negative functions Bn (t) such that for all n âˆˆ N, the function Bn (t)
is nondecreasing in t and Ln â‰¤ L0 (t, x)Bn (t) for all (t, x) âˆˆ Râˆ—+ Ã— R, and
âˆ
X

(Bn (t))1/m < +âˆ,

n=1

for all m âˆˆ Nâˆ— .

Proof. Formula (3.13) clearly holds for n = 0. By induction, suppose that it is true for n.
Now we evaluate Ln+1 (t, x) from the definition and a change of variables (see Figure 2):
Z x+Îºt
Z xâˆ’Îºt
1
Î»2n+4
n
dw wn
du u
Ln+1 (t, x) = (L0 ? Ln ) (t, x) = 3n+4
2
(n!)2 Îºn 2Îº 0
0
n+1

Î»2(n+1)+2 ((Îºt)2 âˆ’ x2 )
= 3(n+1)+2
2
((n + 1)!)2 Îºn+1

for âˆ’Îºt â‰¤ x â‰¤ Îºt, and Ln+1 (t, x) = 0 otherwise. This proves (3.13). The series in (3.14)
converges to the modified Bessel function of order zero by (3.2). As a direct consequence,
2n (Îºt)2n
we have (3.15). Take Bn (t) = 2Î»3n (n!)
2 Îºn , which is non-negative and nondecreasing in t. Then
clearly, Ln (t, x) â‰¤ L0 (t, x)Bn (t). To show the convergence, by the ratio test, for all m âˆˆ Nâˆ— ,
we have that
 âˆš  m2   m2
(Bn (t))1/m
Î» Îºt
1
âˆš
=
â†’ 0,
1/m
n
2 2
(Bnâˆ’1 (t))
as n â†’ âˆ. This completes the proof.

Lemma 3.7. The kernel function K(t, x) defined in (3.1) is strictly increasing in t for x âˆˆ R
fixed and decreasing in |x| for t > 0 fixed. Moreover, for all (s, y) âˆˆ [0, t] Ã— R, we have that

Î»2
Î»2  p
GÎº (s, y) â‰¤ K (s, y) â‰¤ I0 |Î»| Îº/2 t GÎº (s, y) .
2
2

Proof. The first part is true by (3.2). As for the inequalities, the upper bound follows from
the first part. The lower bound is clear since I0 (0) = 1 by (3.2).
Lemma 3.8. Recall the definition of Tk (t, x) in (3.5). For all t âˆˆ R+ , and x, y âˆˆ R,


1
x+y
GÎº (t âˆ’ s, x âˆ’ z)GÎº (t âˆ’ s, y âˆ’ z) = GÎº TÎº (t, x âˆ’ y) âˆ’ s,
âˆ’z ,
(3.16)
2
2
Z
Îº
dz GÎº (t, x âˆ’ z)GÎº (t, y âˆ’ z) = TÎº (t, x âˆ’ y) , and
(3.17)
2
R
ZZ
Îº
(3.18)
dsdz GÎº (t âˆ’ s, x âˆ’ z)GÎº (t âˆ’ s, y âˆ’ z) = TÎº2 (t, x âˆ’ y) .
4
R+ Ã—R
28

s
t

s
TÎº (t, x âˆ’ y)

t

x

x

z

y

|x âˆ’ y|

(a) the case where |x âˆ’ y| â‰¥ 2Îºt

z

y
2ÎºTÎº (t, x âˆ’ y)

|x âˆ’ y|

(b) the case where |x âˆ’ y| < 2Îºt

Figure 3: The two lightly shaded regions denote the support of the functions (s, z) 7â†’
GÎº (t âˆ’ s, x âˆ’ z) and (s, z) 7â†’ GÎº (t âˆ’ s, y âˆ’ z) respectively.
Proof. Since GÎº (t âˆ’ s, x âˆ’ y) = 12 1{Î›(t,x)} (s, y), (3.16)â€“(3.18) are clear from Figure 3.
Proposition 3.9. The wave kernel function GÎº (t, x) satisfies Assumption 2.5 with Ï„ = 1/2,
Î± = Îº/2 and all Î² âˆˆ ]0, 1[ and C = 1.
Proof. See Figure 4. The gray box is the set Bt,x,Î²,Ï„,Î± . Clearly, we need Î±/Îº + Ï„ = 1.
Therefore, we can choose Ï„ = 1/2 and Î± = Îº/2.
s
t+1
Î±/Îº
t+Ï„
t

GÎº (t + 1 âˆ’ s, x âˆ’ y)
GÎº (tâ€² âˆ’ s, xâ€² âˆ’ y)

Î²t

xâˆ’Î±

x

y
x+Î±

Figure 4: GÎº (t, x) verifies Assumption 2.5.
For g âˆˆ L2loc (R) and Âµ âˆˆ M (R), define
Z x
dy g 2 (y), and Î¨âˆ—Âµ (x) = (|Âµ| ([âˆ’x, x]))2 ,
Î¨g (x) =
âˆ’x

for all x â‰¥ 0.

(3.19)

Clearly, these are nondecreasing functions of x.
Lemma 3.10. If g âˆˆ L2loc (R) and Âµ âˆˆ M (R), then for all v âˆˆ R and (t, x) âˆˆ R+ Ã— R,

 2


Îºt2 2
3
v + J02 ? G2Îº (t, x) â‰¤
v + 3Î¨âˆ—Âµ (|x| + Îºt) +
t Î¨g (|x| + Îºt) < +âˆ.
4
16
29

Moreover, for all v âˆˆ R and all compact sets K âŠ† R+ Ã— R,
 2


v + J02 ? G2Îº (t, x) < +âˆ.
sup
(t,x)âˆˆK

Note that the conclusion of this lemma is stronger than Assumption 2.4 since t can be
zero here.
Proof. Suppose t > 0. Notice that |(Âµ âˆ— GÎº (s, Â·))(y)| â‰¤ |Âµ| ([y âˆ’ Îºs, y + Îºs]), and so, recalling
(1.7),

 ZZ
ZZ
 2


1
2
2
2
2
v + J0 ? GÎº (t, x) =
v
dsdy +
dsdy J0 (s, y)
4
Î›(t,x)
Î›(t,x)
Z
Z x+Îº(tâˆ’s)
1 2 2 3 t
â‰¤
v Îºt +
ds
dy g 2 (y + Îºs) + g 2 (y âˆ’ Îºs)
4
4 0
xâˆ’Îº(tâˆ’s)
!

+ 4|Âµ|2 ([y âˆ’ Îºs, y + Îºs])
.
Clearly, for all (s, y) âˆˆ Î›(t, x), by (3.19),
|Âµ|2 ([y âˆ’ Îºs, y + Îºs]) â‰¤ |Âµ|2 ([x âˆ’ Îºt, x + Îºt]) â‰¤ Î¨âˆ—Âµ (|x| + Îºt) .
The integral for g 2 can be easily evaluated by the change of variables in Figure 2:
Z t
0

ds

Z x+Îº(tâˆ’s)
xâˆ’Îº(tâˆ’s)


1
g (y + Îºs) + g (y âˆ’ Îºs) dy =
2Îº
2

2

ZZ

IâˆªIIâˆªIII


g 2 (u) + g 2 (w) dudw

Z âˆ’x+Îºt

1
du g 2 (u) + g 2 (w)
dw
â‰¤
2Îº xâˆ’Îºt
âˆ’xâˆ’Îºt
â‰¤ t Î¨g (|x| + Îºt) ,
Z x+Îºt

where I, II and III denote the three regions in Figure 2 and Î¨g is defined in (3.19).
Therefore,


 2

 2 3

1
2
2
2
âˆ—
v + J0 ? GÎº (t, x) â‰¤
v + 3Î¨Âµ (|x| + Îºt) Îºt + t Î¨g (|x| + Îºt) < +âˆ .
4
4

Finally, let a = sup |x| + Îºt : (t, x) âˆˆ K , which is finite because K is a compact set. Then,
 2



Îºa2 2
3
v + J02 ? G2Îº (t, x) â‰¤
v + 3Î¨âˆ—Âµ (a) +
a Î¨g (a) < +âˆ ,
4
16
(t,x)âˆˆK
sup

which completes the proof of Lemma 3.10.
30

Proof of Theorem 3.1. To apply Theorem 2.13, we need to verify the assumptions (G) and
(W) of Theorem 2.13 with Î¸(t, x) â‰¡ 1. We begin with (G): (a) is satisfied by
ZZ
Îºt2
Î˜Îº (t, x, x) =
dsdy G2Îº (t âˆ’ s, x âˆ’ y) =
< +âˆ
2
[0,t]Ã—R
and Proposition 3.6; (b) is verified by Lemma 3.10. (W) is true due to Proposition 3.9. As
for the two-point correlation function, (2.27) reduces to (3.12) because, by (3.16),


Z t Z
1
x+y
ds dz f (s, z)GÎº (t âˆ’ s, x âˆ’ z)GÎº (t âˆ’ s, y âˆ’ z) = (f ? GÎº ) TÎº (t, x âˆ’ y) ,
.
2
2
0
R
This completes the proof of Theorem 3.1.

3.3

Weak intermittency

Recall that u(t, x) is said to be fully intermittent if the Lyapunov exponent of order 1 vanishes
and the lower Lyapunov exponent of order 2 is strictly positive: m1 = 0 and m2 > 0. The
solution is called weakly intermittent if m2 > 0.
Theorem 3.11. Suppose that |Ï(u)|2 â‰¤ L2Ï (Ï‚ 2 +u2 ), g(x) â‰¡ w and Âµ(dx) = wdx
e
with
w, w
e âˆˆ R. Then we have the following two properties
(1) For all even integers p â‰¥ 2,

ï£± âˆš
3/2
ï£´
ï£²LÏ âˆš2Îº p
mp â‰¤ LÏ Îº p3/2
ï£´
ï£³ p
LÏ Îº/2

if Ï‚ 6= 0 and p > 2,
if Ï‚ = 0 and p > 2,
if p = 2.

(3.20)

e =
6 0 with ww
e â‰¥ 0, then
(2) If |Ï(u)|2 â‰¥ l 2Ï (Ï‚ 2 +u2 ) for some l Ï 6= 0, and if | Ï‚ | + |w| + |w|
p
m2 â‰¥ | l Ï | Îº/2 and so u(t, x) is weakly intermittent.
p
(3) If |Ï(u)|2 = Î»2 (Ï‚ 2 +u2 ), with Î» 6= 0, and if | Ï‚ |+|w|+|w|
e =
6 0, then m2 = m2 = |Î»| Îº/2.

e = 0, then J0 (t, x) â‰¡ 0 and Ï(0) = 0,
Proof. Clearly, J0 (t, x) = w + Îºwt.
e (1) If | Ï‚ | + |w| + |w|
so u(t, x) â‰¡ 0 and the bound is trivially true. If | Ï‚ | + |w| + |w|
e 6= 0, then by (3.7), for all
even integers p â‰¥ 2,


bp (t).
||u(t, x)||2p â‰¤ 2 (w + Îºwt)
e 2 + Ï‚ 2 +2 (w + Îºwt)
e 2 H
p
Hence, by (3.3), mp â‰¤ ap,Ï‚ zp LÏ Îº/2 p/2. Then by (2.15) and the fact that z2 = 1 and
âˆš
zp â‰¤ 2 p for p â‰¥ 2, we obtain (3.20).
31

(2) Note that the term Ï‚ 2 +2 (w + Îºwt)
e 2 on the r.h.s. of the above inequality does not
vanish since | Ï‚ | + |w| + |w|
e =
6 0. By (3.9) and Corollary 3.2,
!


2
2
p
4Îº
w
e
4Îº
w
e
cosh | l Ï | Îº/2 t .
||u(t, x)||22 â‰¥ âˆ’ Ï‚ 2 âˆ’ 2 + w2 + Ï‚ 2 + 2
lÏ
lÏ
p
Clearly, | Ï‚ | + |w| + |w|
e =
6 0 implies that m2 â‰¥ | l Ï | Îº/2.
Part (3) is a consequence of (1) and (2). This completes the proof of Theorem 3.11.

Remark 3.12. It would be interesting to obtain a lower bound of the form mp â‰¥ Cp3/2 .
Dalang and Mueller [23] derived the lower bound for the stochastic wave and heat equations
in R+ Ã— R3 in the case where Ï(u) = Î»u and the driving noise is spatially colored. An
essential tool in their paper is a Feynman-Kac-type formula that they obtained (with Tribe)
in [24].

3.4

Exponential growth indices

Recall the definition of Î»p (x) and Î»p (x) in (1.3) and (1.4). Define


Z
Î²
Î²|x|
MG (R) := Âµ âˆˆ M (R) :
e |Âµ|(dx) < +âˆ ,
R

Î² â‰¥ 0.

(3.21)

We use subscript â€œ+â€ to denote the subset of non-negative measures. For example, M+ (R)
is the set of non-negative Borel measures over R and MÎ²G,+ (R) = MÎ²G (R) âˆ© M+ (R).
Remark 3.13. Since the kernel function K(t, x) has support in the same space-time cone
as the fundamental solution GÎº (t, x), it is clear that if the initial data have compact support, then the solution, including any high peaks related to intermittency, must propagate
in the space-time cone with the same speed Îº. Hence Î»(p) â‰¤ Î»(p) â‰¤ Îº. Conus and Khoshnevisan showed in [18, Theorem 5.1] that with some other mild conditions on the compactly
supported initial data, Î»(p) = Î»(p) = Îº for all p â‰¥ 2.
Theorem 3.14. We have the following:
(1) Suppose that |Ï(u)| â‰¤ LÏ |u| with LÏ 6= 0 and the initial data satisfy the following two
conditions:
(a) The initial position g(x) is a Borel function such that |g(x)| is bounded from above
by some function ceâˆ’Î²1 |x| with c > 0 and Î²1 > 0 for almost all x âˆˆ R;
(b) The initial velocity Âµ âˆˆ MÎ²G2 (R) for some Î²2 > 0.

32

Then for all even integers p â‰¥ 2,
ï£±
!1/2
2
2
2
ï£´
a
z
L
ï£´
p,Ï‚ p
Ï
ï£´
ï£´
ï£´
ï£²Îº 1 + 8Îº (Î²1 âˆ§ Î²2 )2
Î»(p) â‰¤
!1/2
2
ï£´
ï£´
L
ï£´
Ï
ï£´
ï£´
ï£³Îº 1 + 8Îº (Î² âˆ§ Î² )2
1
2

if p > 2,

if p = 2.

(2) Suppose that |Ï(u)| â‰¥ l Ï |u| with l Ï 6= 0 and the initial data satisfy one of the following
two conditions:
(aâ€™) The initial position g(x) is a non-negative Borel function bounded from below by
0
some function c1 eâˆ’Î²1 |x| with c1 > 0 and Î²10 > 0 for almost all x âˆˆ R;

(bâ€™) The initial velocity Âµ(dx) has a density Âµ(x) that is a non-negative Borel function
0
bounded from below by some function c2 eâˆ’Î²2 |x| with c2 > 0 and Î²20 > 0 for almost
all x âˆˆ R.

Then
Î»(p) â‰¥ Îº 1 +

l 2Ï
8Îº (Î²10 âˆ§ Î²20 )2

!1/2

,

for all even integers p â‰¥ 2.

In particular, we have the following two special cases:
(3) For the hyperbolic Anderson model Ï(u) = Î»u with Î» 6= 0, if the initial velocity Âµ
satisfies all Conditions (a), (b), (aâ€™) and (bâ€™) with Î² := Î²1 âˆ§ Î²2 = Î²10 âˆ§ Î²20 , then

1/2
Î»2
.
Î»(2) = Î»(2) = Îº 1 +
8ÎºÎ² 2
(4) If l Ï |u| â‰¤ |Ï(u)| â‰¤ LÏ |u| with l Ï 6= 0 and LÏ 6= 0, and both g(x) and Âµ(x) are nonnegative Borel functions with compact support, then
Î»(p) = Î»(p) = Îº,

for all even integers p â‰¥ 2.

Proof. The statements of (1) and (2) are a consequence of Propositions 3.17 and 3.20 below.
More precisely, let J0,1 (t, x) (resp. J0,2 (t, x)) be the homogeneous solutions obtained with the
initial data g and 0 (resp. 0 and Âµ). Clearly, J0 (t, x) = J0,1 (t, x) + J0,2 (t, x). For the upper
2
2
bounds, we use the fact that J02 (t, x) â‰¤ 2J0,1
(t, x) + 2J0,2
(t, x). By (3.7), we simply choose
the larger of the upper bounds between Proposition 3.17 (1) and Proposition 3.20 (1). As
2
2
for the lower bounds, because both g and Âµ are nonnegative, J02 (t, x) â‰¥ J0,1
(t, x) + J0,2
(t, x).
Hence, by (3.9), we only need to take the larger of the lower bounds between Proposition
3.17 (2) and Proposition 3.20 (2). Part (3) is a direct consequence of (1) and (2). When the
initial data have compact support, both (1) and (2) hold for all Î²i > 0 with i = 1, 2. Then
letting these Î²i â€™s tend to +âˆ proves (4).
33

Note that for Conclusion (3), clearly, Î²i0 â‰¥ Î²i , i = 1, 2. Hence, the condition Î²1 âˆ§ Î²2 =
Î²10 âˆ§ Î²20 has only two possible cases: Î²10 = Î²1 â‰¤ Î²2 â‰¤ Î²20 and Î²20 = Î²2 â‰¤ Î²1 â‰¤ Î²10 .
Remark 3.15. The behaviour of growth indices of the solution to the stochastic wave
equation (1.8) depends on the growth rate of the nonlinearity of Ï, and also on the rate
of decay at Â±âˆ of the initial data. In particular, the initial data significantly affects the
behavior of the solution for all time. However, when the initial data are compactly supported,
the growth rate of the non-linearity Ï plays no role.

3.5

Two propositions for the exponential growth indices

The following asymptotic formula for I0 (x) (see, [38, (10.30.4)]) will be useful
ex
I0 (x) âˆ¼ âˆš
,
2Ï€x
3.5.1

as x â†’ âˆ.

(3.22)

Contributions of the initial position

First consider the case where Âµ â‰¡ 0. Recall that H(t) is the Heaviside function.

Lemma 3.16. Let f (t, x) = 12 eâˆ’Î²|xâˆ’Îºt| + eâˆ’Î²|x+Îºt| H(t). Then we have the following
bounds:
q
Î»2
. For Î² > 0, t â‰¥ 0 and |x| â‰¥ Îºt,
(1) Set Ïƒ := Î² 2 + 2Îº
(f ? K) (t, x) â‰¤

Î»2 t
eâˆ’Î²|x|+ÎºÏƒt .
2(Ïƒ âˆ’ Î²)

(2) For (t, x) âˆˆ Râˆ—+ Ã— R, Î² > 0 and a, b âˆˆ ]0, 1[,
ï£±
 q


ï£´
Î»2 (Îº2 t2 âˆ’x2 )
1 âˆ’Î²Îºt
ï£´
cosh(Î²|x|) I0
âˆ’1
if |x| â‰¤ Îºt,
ï£²2e
2Îº
q

(f ? K) (t, x) â‰¥
ï£´
Î»2 (1âˆ’a2 )
Î»2 eâˆ’Î²|x|
ï£´
b Îºt g(t ; a, b, Î², Îº) if |x| â‰¥ Îºt ,
ï£³ 2(1âˆ’a
2 )Î² 2 Îº I0
2Îº
where the function g (t ; a, b, Î², Îº) is equal to

a cosh (abÎ²Îºt) cosh ((1 âˆ’ b)Î²Îºt) âˆ’ a cosh (aÎ²Îºt) + sinh ((1 âˆ’ b)Î²Îºt) sinh (abÎ²Îºt) .
Proof. (1) Because f (t, â—¦) and K(t, â—¦) are even functions, it suffices to consider
the case

1
Î²(yâˆ’Îºs)
Î²(y+Îºs)
x â‰¤ âˆ’Îºt. In this case, y â‰¤ âˆ’Îºs implies that f (s, y) = 2 e
+e
H(s). Hence,
by (3.4),
!
r
Z
Z x+Îº(tâˆ’s)
2 [Îº2 (t âˆ’ s)2 âˆ’ (x âˆ’ y)2 ]

Î»2 t
1 Î²(yâˆ’Îºs)
Î»
(f ? K) (t, x) â‰¤
ds
dy
e
+ eÎ²(y+Îºs) exp
4 0
2
2Îº
xâˆ’Îº(tâˆ’s)
34

Î»2
=
8

Z t
0


ds eÎ²(xâˆ’Îº(tâˆ’s)) + eÎ²(x+Îº(tâˆ’s))

Z Îºs

âˆ’Îºs

dy exp âˆ’Î²y +

r

Î»2 [Îº2 s2 âˆ’ y 2 ]
2Îº

!

.

1/2

The function Ïˆ(y) := âˆ’Î²y+[Î»2 (Îº2 s2 âˆ’ y 2 )/(2Îº)] achieves its maximum at y = âˆ’Ïƒ âˆ’1 Î²Îºs âˆˆ
[âˆ’Îºs, Îºs], and max|y|â‰¤Îºs Ïˆ(y) = ÏƒÎºs, so
Z

Î»2 Îº t t
ds eÎ²(xâˆ’Îºt)+Îº(Ïƒ+Î²)s + eÎ²(x+Îºt)+Îº(Ïƒâˆ’Î²)s
(f ? K) (t, x) â‰¤
4
0
2

Î»t
Î»2 t
â‰¤
eÎ²(xâˆ’Îºt)+Îº(Ïƒ+Î²)t + eÎ²(x+Îºt)+Îº(Ïƒâˆ’Î²)t =
eÎ²x+ÎºÏƒt .
4(Ïƒ âˆ’ Î²)
2(Ïƒ âˆ’ Î²)

(2) We consider two cases. Case I: |x| â‰¤ Îºt. As shown in Figure 2, we decompose the
space-time convolution into three parts Si corresponding to the three integration regions Di ,
i = 1, 2, 3:
ZZ
3
3
X
X
1
(f ? GÎº ) (t, x) =
Si =
dsdy f (s, y).
2 Di
i=1
i=1

Clearly, (f ? K) (t, x) â‰¥ S3 . Because
f (s, y) â‰¥
we see that


1 âˆ’Î²(Îºtâˆ’x)
e
+ eâˆ’Î²(Îºt+x) ,
2

S3 â‰¥

for all (s, y) âˆˆ D3 ,

2 âˆ’Î²Îºt
e
cosh (Î²x) (L0 ? K) (t, x).
Î»2

Then apply (3.15).
Case II: |x| â‰¥ Îºt. Similar to the proof of part (1), one can assume that x â‰¤ âˆ’Îºt. Then
!
r
Z Îºs
Z

Î»2 t
Î»2 (Îº2 s2 âˆ’ y 2 )
dy I0
ds
(f ? K) (t, x) =
eÎ²(xâˆ’yâˆ’Îº(tâˆ’s)) + eÎ²(xâˆ’y+Îº(tâˆ’s)) .
8 0
2Îº
âˆ’Îºs
Fix a, b âˆˆ ]0, 1[ . Then

!
Î»2 (Îº2 s2 âˆ’ y 2 )
ds
dy I0
eÎ²(xâˆ’y) cosh(Î²Îº(t âˆ’ s))
2Îº
bt
âˆ’aÎºs
!Z
r
Z aÎºs
t
Î»2 eÎ²x
Î»2 (1 âˆ’ a2 )
â‰¥
I0
b Îºt
ds
dy cosh(Î²Îº(t âˆ’ s))eâˆ’Î²y .
4
2Îº
bt
âˆ’aÎºs

Î»2
(f ? K) (t, x) â‰¥
4

Z t

r

Z aÎºs

Since
Z t
bt

ds

Z aÎºs

âˆ’aÎºs

âˆ’Î²y

dy cosh(Î²Îº(t âˆ’ s))e

2
=
Î²

Z t
bt

ds cosh(Î²Îº(t âˆ’ s)) sinh(aÎ²Îºs),

part (2) is proved by an application of the integral in Lemma A.3.
35

Proposition 3.17. Suppose that Âµ â‰¡ 0. Fix Î² > 0. Then:
(1) Suppose |Ï(u)| â‰¤ LÏ |u| with LÏ 6= 0 and let g(x) be a measurable function such that for
some constant C > 0, |g(x)| â‰¤ Ceâˆ’Î²|x| for almost all x âˆˆ R. Then
ï£±
!
2 1/2
2
2
ï£´
a
z
L
ï£´
p,Ï‚ p
Ï
ï£´
ï£´
if p > 2 is an even integer,
ï£´
ï£²Îº 1 + 8ÎºÎ² 2
Î»(p) â‰¤
(3.23)
!1/2
2
ï£´
ï£´
LÏ
ï£´
ï£´
if p = 2 .
ï£´
ï£³Îº 1 + 8ÎºÎ² 2
(2) Suppose |Ï(u)| â‰¥ l Ï |u| with l Ï 6= 0 and let g(x) be a measurable function such that for
some constant c > 0, |g(x)| â‰¥ c eâˆ’Î²|x| for almost all x âˆˆ R. Then
!1/2
l 2Ï
, for all even integers p â‰¥ 2.
(3.24)
Î»(p) â‰¥ Îº 1 +
8ÎºÎ² 2
In particular, if g(x) satisfies both Conditions (1) and (2), and Ï(u) = Î»u with Î» 6= 0, then

1/2
Î»2
.
(3.25)
Î»(2) = Î»(2) = Îº 1 +
8ÎºÎ² 2
Proof. (1) Let J0 (t, x) = 12 (g(x âˆ’ Îºt) + g(x + Îºt)) H(t). By the assumptions on g(x),
|J0 (t, x)|2 â‰¤


C 2 âˆ’2Î²|xâˆ’Îºt|
e
+ eâˆ’2Î²|x+Îºt| H(t),
2

for almost all (t, x) âˆˆ R+ Ã— R.

We first consider the case p > 2. By the moment formula (3.7) and Lemma 3.16 (1), for
|x| â‰¥ Îºt,
||u(t, x)||2p â‰¤ 2J02 (t, x) + C 0 t exp (âˆ’2Î²|x| + ÎºÏƒt) ,
1/2

for some constant C 0 > 0, where Ïƒ := 4Î² 2 + (2Îº)âˆ’1 a2p,Ï‚ zp2 L2Ï
. We only need to consider
the case where Î± > Îº; see Remark 3.13. Because the supremum over |x| â‰¥ Î±t of the
right-hand side is attained at |x| = Î±t,
1
sup log ||u(t, x)||pp â‰¤ âˆ’2Î±Î² + ÎºÏƒ,
tâ†’âˆ t |x|â‰¥Î±t
lim

for Î± > Îº.

Ïƒ
Solve the inequality âˆ’2Î±Î² + ÎºÏƒ < 0 to get Î»(p) â‰¤ Îº 2Î²
, which is the formula in (3.23) for
p > 2. For the case p = 2, we simply replace zp and ap,Ï‚ by 1 (see (2.15)).
(2) Note that Î»(p) â‰¥ Î»(2), because ||u||p â‰¥ ||u||2 for p â‰¥ 2, we only need to consider
p = 2. Assume first that Ï(u) = Î»u. Since |g(x)| â‰¥ c eâˆ’Î²|x| a.e.,

J02 (t, x) â‰¥


c2 âˆ’2Î²|xâˆ’Îºt|
e
+ eâˆ’2Î²|x+Îºt| .
4
36

If |x| â‰¤ Îºt, by (3.9), Lemma 3.7 and Lemma 3.16,

r



c2
||u(t, x)||22 â‰¥ J02 ? K (t, x) â‰¥ eâˆ’2Î²Îºt cosh(2Î²|x|) I0
4

Î»2 (Îº2 t2 âˆ’ x2 )
2Îº

!

!

âˆ’1 .

Hence, for 0 â‰¤ Î± < Îº, by (3.22),

r
1
Îº2 âˆ’ Î±2
lim
sup log ||u(t, x)||22 â‰¥ âˆ’2Î²Îº + 2Î²Î± + |Î»|
.
tâ†’+âˆ t |x|â‰¥Î±t
2Îº

Then
|Î»| âˆš 2
h(Î±) := âˆ’2Î²Îº + 2Î²Î± + âˆš
Îº âˆ’ Î±2 â‰¥ 0
2Îº

â‡”

Îº

8ÎºÎ² 2 âˆ’ Î»2
â‰¤ Î± â‰¤ Îº.
8ÎºÎ² 2 + Î»2

As Î± tends to Îº from the left side, h(Î±) remains positive. Therefore, Î»(2) â‰¥ Îº.
If x â‰¤ âˆ’Îºt, again, by Lemma 3.16,
!
r
2 2 âˆ’2Î²|x|
2 (1 âˆ’ a2 )
Î»
c
Î»
e
I0
bÎºt g(t ; a, b, 2Î², Îº), for all a, b âˆˆ ]0, 1[.
||u(t, x)||22 â‰¥
4(1 âˆ’ a2 )(2Î²)2 Îº
2Îº
For large t, replace both cosh(Ct) and sinh(Ct) by exp(Ct)/2, with C â‰¥ 0, to see that
g(t ; a, b, 2Î², Îº) â‰¥ C 0 exp (2(1 + (a âˆ’ 1)b)tÎ²Îº) ,

for some constant C 0 > 0. Hence, for Î± > Îº, by (3.22),
r
1
Î»2 (1 âˆ’ a2 )
lim sup log ||u(t, x)||22 â‰¥
bÎº âˆ’ 2Î²Î± + 2(1 âˆ’ (1 âˆ’ a)b)Î²Îº .
tâ†’âˆ t |x|â‰¥Î±t
2Îº
Solve the inequality
h(Î±) :=

r

to get
Î±<

Î»2 (1 âˆ’ a2 )
bÎº âˆ’ 2Î²Î± + 2(1 âˆ’ (1 âˆ’ a)b)Î²Îº > 0
2Îº
r

!
Î»2 (1 âˆ’ a2 ) b
+ 1 âˆ’ (1 âˆ’ a)b Îº.
2Îº
2Î²

Since a âˆˆ ]0, 1[ is arbitrary, we can choose
! 
r
âˆ’1/2
Î»2 (1 âˆ’ a2 ) b
Î»2
a := arg max
+ 1 âˆ’ (1 âˆ’ a)b = 1 +
.
2Îº
2Î²
8ÎºÎ² 2
aâˆˆ ]0,1[
1/2

In this case, the critical growth rate is Î± = bÎº [1 + Î»2 /(8ÎºÎ² 2 )] + (1 âˆ’ b)Îº. Finally, since b
1/2
can be arbitrarily close to 1, we have that Î»(2) â‰¥ Îº [1 + Î»2 /(8ÎºÎ² 2 )] , and for the general

1/2
case |Ï(u)| â‰¥ l Ï |u|, we have that Î»(p) â‰¥ Î»(2) â‰¥ Îº 1 + l 2Ï /(8ÎºÎ² 2 )
. This completes the
proof of Proposition 3.17.
37

3.5.2

Contributions of the initial velocity

Now, let us consider the case where g(x) â‰¡ 0. We shall first study the case where Âµ(dx) =
eâˆ’Î²|x| dx with Î² > 0. In this case, J0 (t, x) is given by the following lemma.
Lemma 3.18. Suppose that Âµ(dx) = eâˆ’Î²|x| dx with Î² > 0. For all (t, x) âˆˆ R+ Ã— R and z > 0,
(

2Î² âˆ’1 eâˆ’Î²|x| sinh(Î²z)
|x| â‰¥ z,

Âµ âˆ— 1{|Â·|â‰¤z} (x) =
âˆ’Î²z
âˆ’1
1âˆ’e
cosh(Î²x) |x| â‰¤ z.
2Î²
(
Î² âˆ’1 eâˆ’Î²|x| sinh(Î²Îºt)

In particular, we have that J0 (t, x) =
Î² âˆ’1 1 âˆ’ eâˆ’Î²Îºt cosh(Î²x)

|x| â‰¥ Îºt,
|x| â‰¤ Îºt.

The proof is straightforward, and is left to the reader (see also [10, Lemma 4.4.5]).

Lemma 3.19. Suppose that Âµ âˆˆ MÎ²G (R) with Î² > 0. Set h(t, x) = (Âµ âˆ— GÎº (t, Â·)) (x) and
1/2
Ïƒ = [Î² 2 + (2Îº)âˆ’1 Î»2 ] . Then for all t â‰¥ 0 and x âˆˆ R,
Z
|h(t, x)| â‰¤ C exp (Î²Îºt âˆ’ Î²|x|) , with C = 1/2 |Âµ|(dx) eÎ²|x| ,
R

and
Î»2 t
(|h| ? K) (t, x) â‰¤
eâˆ’Î²|x|+ÏƒÎºt .
2(Ïƒ âˆ’ Î²)
Proof. Considering the first inequality, observe that
Z
Z
1 x+Îºt
1 x+Îºt
Î²|x|
Î²|x|
|Âµ|(dy) e
â‰¤
|Âµ|(dy) eÎ²|xâˆ’y| eÎ²|y|
e |(Âµ âˆ— GÎº (t, Â·)) (x)| â‰¤
2 xâˆ’Îºt
2 xâˆ’Îºt
Z
Z
1 Î²Îºt x+Îºt
1 Î²Îºt
Î²|y|
â‰¤ e
|Âµ|(dy) e
â‰¤ e
|Âµ|(dy) eÎ²|y| .
2
2
xâˆ’Îºt
R
For the second inequality, set f (t, x) = eÎ²Îºtâˆ’Î²|x| . Then by (3.4),
!
2 (Îº2 s2 âˆ’ y 2 )
Î»
dy exp âˆ’Î²|x âˆ’ y| +
ds eÎ²Îº(tâˆ’s)
2Îº
âˆ’Îºs
0
!
r
Z
Z Îºs
2 (Îº2 s2 âˆ’ y 2 )
Î»2 t
Î»
â‰¤
dy exp âˆ’Î²|x| + Î²|y| +
ds eÎ²Îº(tâˆ’s)
4 0
2Îº
âˆ’Îºs
!
r
Z
Z Îºs
2 (Îº2 s2 âˆ’ y 2 )
Î»2 âˆ’Î²|x| t
Î»
â‰¤ e
ds eÎ²Îº(tâˆ’s)
dy exp Î²y +
.
2
2Îº
0
0

Î»2
(f ? K) (t, x) =
4

Z t

r

Z Îºs

38

1/2

The function Ïˆ(y) := Î²y + [Î»2 (Îº2 s2 âˆ’ y 2 ) /(2Îº)]
[0, Îºs], and maxyâˆˆ[0,Îºs] Ïˆ(y) = ÏƒÎºs, so
Î»2 Îºt âˆ’Î²|x|
(f ? K) â‰¤
e
2

Z t
0

achieves its maximum at y = Ïƒ âˆ’1 Î²Îºs âˆˆ

ds eÎ²Îº(tâˆ’s)+ÏƒÎºs â‰¤

Î»2 t
eâˆ’Î²|x|+ÏƒÎºt .
2(Ïƒ âˆ’ Î²)

This completes the proof.
Proposition 3.20. Suppose that g â‰¡ 0. Fix Î² > 0.
(1) If |Ï(u)| â‰¤ LÏ |u| with LÏ 6= 0 and Âµ âˆˆ MÎ²G (R), then Î»(p) satisfies (3.23).
(2) Suppose that |Ï(u)| â‰¥ l Ï |u| with l Ï 6= 0 and Âµ(dx) = f (x)dx. If for some constant c > 0,
f (x) â‰¥ ceâˆ’Î²|x| for all almost all x âˆˆ R, then Î»(p) satisfies (3.24).
In particular, if Âµ satisfies both Conditions (1) and (2), and Ï(u) = Î»u with Î» 6= 0, then
(3.25) holds.
Proof. (1) Let p > 2 be an even integer. Let h(t, x) be the function defined in Lemma 3.19.
Notice that the first bound in Lemma 3.19 is satisfied by h2 (t, x) provided Î² is replaced by
2Î². By (3.7) and Lemma 3.19, we see that for some constant C 0 > 0,
||u(t, x)||2p â‰¤ 2h2 (t, x) + C 0 t exp (âˆ’2Î²|x| + ÎºÏƒt) ,


1/2
where Ïƒ = 4Î² 2 + a2p,Ï‚ zp2 L2Ï /(2Îº)
. Then it is clear that

1
sup log ||u(t, x)||pp â‰¤ âˆ’2Î²Î± + ÎºÏƒ.
tâ†’âˆ t |x|â‰¥Î±t
lim

Ïƒ
Solve the inequality âˆ’2Î²Î± + ÎºÏƒ > 0 to get Î»(p) â‰¤ Îº 2Î²
. For the case p = 2, simply replace
zp and ap,Ï‚ by 1.
(2) Suppose that f (x) â‰¥ eâˆ’Î²|x| for almost all x âˆˆ R (i.e., set c = 1). By (3.9) and (3.11),
we may only consider the case where Ï(u) = Î»u. Denote J0 (t, x) = (eâˆ’Î²|Â·| âˆ— GÎº (t, Â·))(x). We
first consider the case where |x| â‰¤ Îºt. As shown in Figure 2, split the integral that defines
(J02 ? K) (t, x) over the three regions I, II, and III, so that

||u(t, x)||22 â‰¥ J02 ? K (t, x) = S1 + S2 + S3 â‰¥ S3 .

For arbitrary a, b âˆˆ ]0, 1[, we see that
Î»2
S3 â‰¥
4

Z t
bt

ds

Z aÎºs

âˆ’aÎºs

Z
Î»2 t
â‰¥
ds I0
4 bt

dy J02 (t âˆ’ s, x âˆ’ y) I0

r

r

Î»2 ((Îºs)2 âˆ’ y 2 )
2Îº

!

!Z
aÎºs
Î»2 (1 âˆ’ a2 )
Îºs
dy J02 (t âˆ’ s, x âˆ’ y)
2Îº
âˆ’aÎºs
39

Î»2
â‰¥ I0
4

r

!Z
Z abÎºt
t
Î»2 (1 âˆ’ a2 )
Îºbt
ds
dy J02 (t âˆ’ s, x âˆ’ y) .
2Îº
bt
âˆ’abÎºt

Clearly, for (s, y) in Region III of Figure 2, |x âˆ’ y| â‰¤ Îº(t âˆ’ s) and so by Lemma 3.18,

J0 (t âˆ’ s, x âˆ’ y) = 1 âˆ’ eâˆ’Î²Îº(tâˆ’s) cosh (Î²(x âˆ’ y)) /Î².
2

Using the inequalities (a + b)2 â‰¥ a2 âˆ’ b2 and cosh2 (x) = 21 (cosh(2x) + 1) â‰¥ 21 cosh(2x),
J02 (t âˆ’ s, x âˆ’ y) â‰¥

1 âˆ’2Î²Îº(tâˆ’s)
1
e
cosh(2Î²(x âˆ’ y)) âˆ’ 2 .
2
4Î²
Î²

Hence,

Z t Z abÎºt
âˆ’2(1âˆ’b)Î²Îºt
1
âˆ’
e
cosh(2Î²x) sinh(2abÎ²Îºt) 2a(1 âˆ’ b)bÎºt2
dy J02 (t âˆ’ s, x âˆ’ y) â‰¥
âˆ’
ds
.
8Î² 4 Îº
Î²2
âˆ’abÎºt
bt
Therefore, by (3.22),
p
âˆš
1
sup log ||u(t, x)||22 â‰¥ 2Î²Î± + 2abÎ²Îº + b|Î»| Îº/2 1 âˆ’ a2 > 0,
tâ†’+âˆ t |x|â‰¥Î±t
lim

(3.26)

for Î± â‰¤ Îº and all a, b âˆˆ ]0, 1[ , which implies that Î»(2) â‰¥ Îº. As for the case where |x| â‰¥ Îºt,
for all a, b âˆˆ ]0, 1[, by Lemma 3.18,

||u(t, x)||22 â‰¥ J02 ? K (t, x)
!
r
Z Îºs
Z t
2 (Îº2 s2 âˆ’ y 2 )
Î»2
Î»
dy eâˆ’2Î²|xâˆ’y| I0
=
ds sinh2 (Î²Îº(t âˆ’ s))
16Î² 2 0
2Îº
âˆ’Îºs
!
r


Î»2 (1 âˆ’ a2 )
Î»2 eâˆ’2Î²|x|+2aÎºbtÎ² sinh(2(1 âˆ’ b)Î²Îºt) 1
âˆ’ (1 âˆ’ b)t I0
bÎºt .
â‰¥
32Î² 3
4Î²Îº
2
2Îº
Therefore, for Î± > Îº, we obtain the same inequality as (3.26). The rest argument is exactly
the same as the proof of part (2) of Proposition 3.17. This completes the proof of Proposition
3.20.

4

HoÌˆlder continuity in the stochastic wave equation

Theorem 4.1. Suppose that Ï is Lipschitz continuous. If g âˆˆ L2Î³
loc (R), Î³ â‰¥ 1 and Âµ âˆˆ M (R),
then for all compact sets K âˆˆ R+ Ã— R and all p â‰¥ 1, there is a constant CK,p such that for
all (t, x), (t0 , x0 ) âˆˆ K,


0
0
||I(t, x) âˆ’ I(t0 , x0 )||p â‰¤ CK,p |t âˆ’ t0 |1/(2Î³ ) + |x âˆ’ x0 |1/(2Î³ ) ,
40

where Î³1 + Î³10 = 1. Hence,
I(t, x) âˆˆ C 1 0 âˆ’, 1 0 âˆ’ (R+ Ã— R) a.s.
2Î³

2Î³

In addition, for all compact sets K âˆˆ R+ Ã— R and 0 â‰¤ Î± < 1/(2Î³ 0 ) âˆ’ 2/p,
ï£®ï£«
ï£¶p ï£¹
ï£¯ï£¬
ï£¬
Eï£¯
ï£°ï£­

ï£º
|I(t, x) âˆ’ I(s, y)| ï£·
ï£· ï£º
Î± ï£¸ ï£» < +âˆ.
(t,x), (s,y)âˆˆK [|t âˆ’ s| + |x âˆ’ y|]
sup

(t,x)6=(s,y)

In particular, if g is locally bounded (Î³ = +âˆ), then I(t, x) âˆˆ C 1 âˆ’, 1 âˆ’ (R+ Ã— R) a.s.
2

2

Proof. We only need to verify that Assumption 2.14 holds for Kn = [0, n] Ã— [âˆ’n, n]. This is
the case thanks to Propositions 4.5 â€“ 4.7 below. More precisely, let J0,1 (t, x) and J0,2 (t, x)
be the homogeneous solutions contributed respectively by g and Âµ. Clearly, when both
2
(t, x) +
g and Âµ are nonvanishing, J0 (t, x) = J0,1 (t, x) + J0,2 (t, x). Because J02 (t, x) â‰¤ 2J0,1
2
2J0,2 (t, x), we can consider J0,1 (t, x) and J0,2 (t, x) separately when verifying Assumption 2.14.
In particular, Proposition 4.5 shows that the contribution of J0,2 (t, x) satisfies Assumption
2.14, and Propositions 4.6 and 4.7 guarantee that the contribution of J0,1 (t, x) satisfies
Assumption 2.14.
Proposition 4.2. Suppose that |Ï(u)|2 = Î»2 (Ï‚ 2 +u2 ). If g(x) = |x|âˆ’a with a âˆˆ [0, 1/2[ and
Âµ â‰¡ 0, then in the neighborhood of the two characteristic lines |x| = Îºt, the function I(t, x)
mapping from R+ Ã— R into Lp (â„¦), p â‰¥ 2, cannot be Ï-HoÌˆlder continuous either in space or
.
in time with Ï > 1âˆ’2a
2
This proposition is proved in Section 4.2.
Remark 4.3 (Optimal Lp (â„¦)-HoÌˆlder continuity). Clearly, |x|âˆ’a âˆˆ L2Î³
loc (R) if and only if
âˆ’1
0
2Î³a < 1, i.e., Î³ < (2a) . Hence, Î³ , the dual of Î³, is strictly bigger than (1 âˆ’ 2a)âˆ’1 .
Therefore, according to Theorem 4.1, for all p â‰¥ 2, the function I : R+ Ã— R 7â†’ Lp (â„¦) is
jointly Î·-HoÌˆlder continuous with Î· = (1 âˆ’ 2a)/2. For example, if a = 1/4 (see Example
3.4), then I is jointly 1/4-HoÌˆlder continuous in Lp (â„¦). Proposition 4.2 then shows that
I(t, x) cannot be jointly Î·-HoÌˆlder continuous with Î· > 1/4. Hence, the estimates on the
joint Lp (â„¦)-HoÌˆlder continuity are optimal. Singularities in the initial conditions affect the
regularity of deviations from the homogeneous solution.

4.1

Three propositions for the HoÌˆlder continuity

In this part, we will prove Propositions 4.5 â€“ 4.7, which together verify Assumption 2.14
(and hence the HoÌˆlder continuity).

41

Proposition 4.4. For T > 0, we have that
Z
Z
2
ds dy (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y)) â‰¤ CT (|x0 âˆ’ x| + |t0 âˆ’ t|) ,
R+

R

for all (t, x) and (t0 , x0 ) âˆˆ ]0, T ] Ã— R, with CT := (Îº âˆ¨ 1) T /2.
The proof of this proposition is elementary.
Proposition 4.5. Denote Knâˆ— := [0, n] Ã— [âˆ’n âˆ’ Îºn, n + Îºn]. Suppose that
sup J02 (t, x) < +âˆ,

for all n > 0.

(4.1)

âˆ—
(t,x)âˆˆKn

Then Assumption 2.14 holds under the settings: Î¸(t, x) â‰¡ 1, d = 1, Î³0 = Î³1 = 1, and
Kn = [0, n] Ã— [âˆ’n, n]. Condition (4.1) (and hence Assumption (2.14)) holds in particular
when g â‰¡ 0 and Âµ is a locally finite Borel measure:
sup J02 (t, x) â‰¤ 1/4 Î¨âˆ—Âµ (n + 2Îºn) < +âˆ.

âˆ—
(t,x)âˆˆKn

Proof. Fix v â‰¥ 0, n > 1 and choose arbitrary (t, x) and (t0 , x0 ) âˆˆ Kn = [0, n] Ã— [âˆ’n, n]
(note that the time variable can be zero). Because the support of the function (s, y) 7â†’
GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y) is included in the compact set Knâˆ— , by Proposition 4.4,
the l.h.s. of (2.28) is bounded by,
ZZ
n (Îº âˆ¨ 1)
2
Cn
dsdy (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y)) â‰¤ Cn
(|x âˆ’ x0 | + |t âˆ’ t0 |) ,
2
R+ Ã—R
where Cn = sup(s,y)âˆˆKnâˆ— (v 2 + 2J02 (s, y)). As for (2.29), using the same constant Cn , the l.h.s.
of (2.29) is bounded by
Cn

ZZ

dsdy
R+ Ã—R

Z Z

R+ Ã—R



dudz G2Îº (s âˆ’ u, y âˆ’ z)

Cn Îºn2
â‰¤
4

ZZ

R+ Ã—R

2

(GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y))

dsdy (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y))2 .

Then apply Proposition 4.4 as before.
Proposition 4.6. Suppose Âµ â‰¡ 0 and g âˆˆ L2loc (R). Then (2.29) holds with Î¸(t, x) â‰¡ 1,
d = 1, Î³0 = Î³1 = 1, and Kn = [0, n] Ã— [âˆ’n, n].
Proof. Split (2.29) into two parts by linearity: one term is contributed by v 2 and the other
by 2J02 . Proposition 4.5 shows that the first term satisfies Assumption 2.14. Hence, we only

42

need to consider the second term. Let Knâˆ— = [0, n] Ã— [âˆ’(1 + Îº)n, (1 + Îº)n]. By a change of
variables (see Figure 2), for all (t, x) âˆˆ Knâˆ— ,
ZZ

1 1
(1 + Îº)n
2
2
J0 ? GÎº (t, x) =
Î¨g (n + nÎº),
dudw (g(w) + g(u))2 â‰¤
16 2Îº IâˆªIIâˆªIII
4Îº

where I, II and III denote the three domains shown in Figure 2. Therefore, this proposition
is proved by applying Proposition 4.5.

0
Proposition 4.7. Suppose Âµ â‰¡ 0, g âˆˆ L2Î³
loc (R) with Î³ â‰¥ 1, and 1/Î³ + 1/Î³ = 1. Then (2.28)
holds with Î¸(t, x) â‰¡ 1, d = 1, and Î³0 = Î³1 = 1/Î³ 0 .

Proof. Equivalently, we shall show that (2.30)â€“(2.32) hold under the same settings. As
explained in the proof of Proposition 4.6, we can assume that v = 0 in (2.30)â€“(2.32). Fix
n > 0, (t, x) and (t0 , x0 ) âˆˆ Kn = [0, n] Ã— [âˆ’n, n] with t â‰¤ t0 . We first prove (2.30). Because
the support of the function GÎº âˆ’ GÎº is in Knâˆ— = [0, n] Ã— [âˆ’(1 + Îº)n, (1 + Îº)n], by HoÌˆlderâ€™s
inequality,
Z t Z
2
ds dy J02 (s, y) (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x âˆ’ y))
I :=
0

â‰¤

Z t

R

ds

0

Z (1+Îº)n

!1/Î³ Z

dy J02Î³ (s, y)

âˆ’(1+Îº)n

R

2Î³ 0

0

dy |GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t âˆ’ s, x âˆ’ y)|

1/Î³ 0

By convexity of x 7â†’ |x|2Î³ ,
Z (1+Îº)n
Z

1 (1+Îº)n
2Î³
dy J0 (s, y) â‰¤
dy g 2Î³ (y + Îºs) + g 2Î³ (y âˆ’ Îºs) â‰¤ Î¨gÎ³ (n + 2Îºn).
2 âˆ’(1+Îº)n
âˆ’(1+Îº)n
Hence,

1
Î³
gÎ³

I â‰¤ Î¨ (n + 2Îºn)
where

Z

R

Therefore,

Z t

ds

0

Z

R

dy |GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t âˆ’ s, x âˆ’ y)|
2Î³ 0

dy |GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x âˆ’ y)|
0

Iâ‰¤

2Î³ 0

0

0

= 2âˆ’2Î³ Îºn |t0 âˆ’ t| .

0

Îº1/Î³ n1+1/Î³ Î³1
1/Î³ 0
Î¨gÎ³ (n + 2Îºn) |t0 âˆ’ t|
,
4

which proves (2.30).
Now let us consider (2.31). As above, we can assume that v = 0, so we set
Z t Z
I :=
ds dy J02 (s, y) (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t âˆ’ s, x0 âˆ’ y))2
0

R

43

1/Î³ 0

,

.

1
Î³
gÎ³

â‰¤ Î¨ (n + 2Îºn)

Z t

ds

0

Z

R

2Î³ 0

0

dy |GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t âˆ’ s, x âˆ’ y)|

where (see Figure 3),
Z
2Î³ 0
dy |GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t âˆ’ s, x0 âˆ’ y)|

1/Î³ 0

,

R

0

0

0

= 21âˆ’2Î³ |x0 âˆ’ x| 1{|x0 âˆ’x|â‰¤2Îº(tâˆ’s)} + 21âˆ’2Î³ Îº(t âˆ’ s) 1{|x0 âˆ’x|>2Îº(tâˆ’s)} â‰¤ 21âˆ’2Î³ |x0 âˆ’ x| .

Therefore,
0

1

1/Î³ 0

I â‰¤ 2âˆ’2+1/Î³ n Î¨gÎ³Î³ (n + 2Îºn) |x0 âˆ’ x|

,

which proves (2.31).
Now let us consider (2.32). By the same arguments as above, we only consider
Z t0 Z
I :=
ds dy J02 (s, y) G2Îº (t0 âˆ’ s, x0 âˆ’ y)
t

R

1
Î³
gÎ³

â‰¤ Î¨ (n + 2Îºn)
where

Z

R

Therefore,

Z t0
t

ds

Z

R

0
0
0
dy G2Î³
Îº (t âˆ’ s, x âˆ’ y)

0

0

1/Î³ 0

,

0

0
0
âˆ’2Î³
dy G2Î³
2Îº(t0 âˆ’ s) â‰¤ 2âˆ’2Î³ 2Îºn.
Îº (t âˆ’ s, x âˆ’ y) = 2

0

0

1

I â‰¤ 2âˆ’2+1/Î³ (nÎº)1/Î³ Î¨gÎ³Î³ (n + 2Îºn) |t0 âˆ’ t| .
0

Finally, (2.32) follows from the bound |t0 âˆ’ t| â‰¤ n1/Î³ |t0 âˆ’ t|1/Î³ .

4.2

Optimality of the HoÌˆlder exponents (proof of Proposition 4.2)

Lemma 4.8. If g(x) = |x|âˆ’a with a âˆˆ [0, 1/2[ and Âµ â‰¡ 0, then
ï£±
2(1âˆ’a)
a2 âˆ’4a+2
ï£´
,
if x < âˆ’Îºt,
2 |Îºt âˆ’ x|
ï£´
32Îº(1âˆ’2a)(1âˆ’a)
ï£´


ï£´
2
1âˆ’a
1âˆ’a
ï£²
1

+ (Îºt + x)
2 (Îºt âˆ’ x)

J02 ? G2Îº (t, x) = 32Îº(1âˆ’a) t
1âˆ’2a
1âˆ’2a 
ï£´
(Îºt
âˆ’
x)
+
(Îºt
+
x)
, if |x| â‰¤ Îºt,
+
ï£´
16(1âˆ’2a)
ï£´
ï£´
2(1âˆ’a)
ï£³ a2 âˆ’4a+2
|Îºt + x|
,
if x > Îºt,
32Îº(1âˆ’2a)(1âˆ’a)2
where J0 (t, x) = (g (x âˆ’ Îºt) + g (x + Îºt)) /2.

Proof. First assume that |x| â‰¤ Îºt. Then
Z t Z x+Îº(tâˆ’s)

1
1
2
2
J0 ? GÎº (t, x) =
ds
dy (g(y âˆ’ Îºs) + g(y + Îºs))2 =
(S1 + S2 + S3 ) ,
16 0
16
xâˆ’Îº(tâˆ’s)
44

where S1 , S2 and S3 correspond to the integrations in the regions I, II and III shown in
Figure 2. To evaluate these three integrals, by change the variables (see Figure 2),
Z âˆ’x+Îºt
Z 0
2
1
a2 âˆ’ 4a + 2
S1 =
du |u|âˆ’a + |w|âˆ’a =
dw
(Îºt âˆ’ x)2(1âˆ’a) ,
2
2Îº xâˆ’Îºt
2Îº(1
âˆ’
2a)(1
âˆ’
a)
âˆ’w
Z 0
Z x+Îºt
2
a2 âˆ’ 4a + 2
1
dw
du |u|âˆ’a + |w|âˆ’a =
S2 =
(Îºt + x)2(1âˆ’a) ,
2
2Îº 0
2Îº(1 âˆ’ 2a)(1 âˆ’ a)
âˆ’w


1
1
1âˆ’2a
1âˆ’2a
2 2
2 1âˆ’a
+
Îº
t
âˆ’
x
(Îºt
âˆ’
x)
(Îºt
+
x)
+
(Îºt
+
x)
(Îºt
âˆ’
x)
.
S3 =
Îº(1 âˆ’ a)2
2Îº(1 âˆ’ 2a)

Use the fact that

a2 âˆ’ 4a + 2
(1 âˆ’ 2a) + (1 âˆ’ a)2
1
1
=
=
+
2
2
2
2Îº(1 âˆ’ 2a)(1 âˆ’ a)
2Îº(1 âˆ’ 2a)(1 âˆ’ a)
2Îº(1 âˆ’ a)
2Îº(1 âˆ’ 2a)
to sum up these Si . The other two cases, x < âˆ’Îºt and x > Îºt, can be calculated similarly
to S1 and S2 respectively.
Proof of Proposition 4.2. Let I(t, x) be the stochastic integral part of random field solution,
i.e., u(t, x) = J0 (t, x) + I(t, x). For (t, x) and (t0 , x0 ) âˆˆ R+ Ã— R, because
Ï‚ 2 + ||u (s, y)||22 â‰¥ J02 (s, y) ,

and

2

2

||I(t, x) âˆ’ I(t0 , x0 )||p â‰¥ ||I(t, x) âˆ’ I(t0 , x0 )||2

for p â‰¥ 2, we see that
2

||I(t, x) âˆ’ I(t0 , x0 )||p
ZZ
2
â‰¥Î»

2

R+ Ã—R

dsdy (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ GÎº (t0 âˆ’ s, x0 âˆ’ y)) J02 (s, y) .

(4.2)

Spatial increments. Fix t = t0 > 0, x and x0 âˆˆ R. Denote T = TÎº (t, x âˆ’ x0 ). By (3.16), the
lower bound in (4.2) reduces to


ZZ
x + x0
2
2
2
2
âˆ’ y + G2Îº (t âˆ’ s, x0 âˆ’ y)),
Î»
dsdy J0 (s, y) (GÎº (t âˆ’ s, x âˆ’ y) âˆ’ 2GÎº T âˆ’ s,
2
R+ Ã—R
which is denoted by Î»2 L(t, x, x0 ). Then
0

L(t, x, x ) =

J02 ? G2Îº



(t, x) +

J02 ? G2Îº



0

(t, x ) âˆ’ 2

J02 ? G2Îº





x + x0
T,
2



.

Let x = Îºt and x0 < x be such that |x0 âˆ’ x| â‰¤ 2Îºt. Hence, TÎº (t, x âˆ’ x0 ) = t âˆ’ (x âˆ’ x0 )/(2Îº).
Then apply Lemma 4.8 to see that
L(t, Îºt, x0 ) =

1
t
L1 (t, x0 ) +
L2 (t, x0 ),
2
32Îº(1 âˆ’ a)
16(1 âˆ’ 2a)
45

with
i2
h
1âˆ’a
1âˆ’a
2(1âˆ’a)
L1 (t, x0 ) = (2Îºt)2(1âˆ’a) + (Îºt âˆ’ x0 )
+ (Îºt + x0 )
âˆ’ 2 (Îºt + x0 )
,
L2 (t, x0 ) = (2Îºt)1âˆ’2a + (Îºt âˆ’ x0 )1âˆ’2a âˆ’ (Îºt + x0 )1âˆ’2a .

Let h = Îºt âˆ’ x0 . Then

2

L1 (t, x0 ) = (2Îºt)2(1âˆ’a) + h1âˆ’a + (2Îºt âˆ’ h)1âˆ’a âˆ’ 2 (2Îºt âˆ’ h)2(1âˆ’a) â‰¥ h2(1âˆ’a) ,

L2 (t, x0 ) = (2Îºt)1âˆ’2a + h1âˆ’2a âˆ’ (2Îºt âˆ’ h)1âˆ’2a â‰¥ h1âˆ’2a .

Since 1 âˆ’ 2a âˆˆ ]0, 1] and 2(1 âˆ’ a) âˆˆ ]1, 2], by discarding L1 (t, x0 ), we have that
||I(t, Îºt) âˆ’ I(t, Îºt âˆ’ h)||2p = Î»2 L(t, Îºt, x0 ) â‰¥

Î»2 t
h1âˆ’2a .
16(1 âˆ’ 2a)

Time increments. Now fix x = x0 âˆˆ R. By symmetry, we assume that x > 0 . For t0 â‰¥ t â‰¥ 0,
(4.2) implies that



2
||I(t, x) âˆ’ I(t0 , x)||p â‰¥ Î»2 J02 ? G2Îº (t0 , x) âˆ’ J02 ? G2Îº (t, x) ,

because GÎº (t, x)GÎº (t0 , x) = G2Îº (t, x). Take t = x/Îº and h = t0 âˆ’ t = t0 âˆ’ x/Îº. Similarly to
the previous case,
 x 
1
x
2(1âˆ’a)
2
2
,x =
(2x)
+
(2x)1âˆ’2a ,
J0 ? GÎº
2
Îº
32Îº(1 âˆ’ a)
16Îº(1 âˆ’ 2a)
and (J02 ? G2Îº ) (t0 , x) is equal to



1
x
1âˆ’a
1âˆ’a 2
1âˆ’2a
1âˆ’2a 
(Îºh)
+
(Îºh
+
2x)
+
(Îºh)
+
(Îºh
+
2x)
.
32Îº(1 âˆ’ a)2
16Îº(1 âˆ’ 2a)

Hence, by symmetry, for all x âˆˆ R, and h = t0 âˆ’ |x|/Îº > 0,
I




2
Î»2 |x|
|x|
0
, x âˆ’ I(t , x) â‰¥
h1âˆ’2a .
2a (1 âˆ’ 2a)
Îº
16Îº
p

Therefore, Proposition 4.2 is proved.

A

Some technical lemmas

Rt
Rt
Lemma A.1. For a 6= 0 and t â‰¥ 0, 0 ds cosh(as)(tâˆ’s) = aâˆ’2 (cosh(at) âˆ’ 1), 0 ds sinh(as)(tâˆ’
Rt
s) = aâˆ’2 (sinh(at) âˆ’ at), and 0 ds sinh(as)(t âˆ’ s)2 = aâˆ’3 (2 cosh(at) âˆ’ a2 t2 âˆ’ 2).
46

Lemma A.2. For t â‰¥ 0 and x âˆˆ R, we have that
and (1 ? K) (t, x) = cosh |Î»| (Îº/2)1/2 t âˆ’ 1.

R

R


dxK(t, x) = |Î»|(Îº/2)1/2 sinh |Î»| (Îº/2)1/2 t

Proof. By a change of variable,
Z

R

dx K(t, x) = 2

Z |Î»|âˆšÎº/2 t
0

âˆš
Î»2 2Îº
y
p
dy
I0 (y).
2
2
4 |Î»|
Îºt Î» /2 âˆ’ y 2

Then the first statement follows from [28, (6) on p. 365] with Î½ = 0, Ïƒ = 1/2 and a =
|Î»| (Îº/2)1/2 t. The second statement is a simple application of the first.
Lemma A.3. Suppose that a 6= c, t > 0 and b âˆˆ [0, 1]. Then
Z t
bt

ds cosh (a(t âˆ’ s)) sinh (cs)

 
2
2 âˆ’1
= a âˆ’c
c cosh(bct) cosh (a(1 âˆ’ b)t) âˆ’ c cosh(ct) + a sinh(bct) sinh (a(1 âˆ’ b)t) .

Proof. Use the formula cosh(x) sinh(y) = 12 (sinh(x + y) + sinh(âˆ’x + y)).

For the following two lemmas, let GÎ½ (t, x), Î½ > 0, be the heat kernel function (see (2.37)).
1
Lemma A.4. For all t, s > 0 and x, y âˆˆ R, we have that G2Î½ (t, x) = âˆš4Ï€Î½t
GÎ½/2 (t, x) and

ts sx+ty
GÎ½ (t, x)GÎ½ (s, y) = GÎ½ t+s , t+s GÎ½ (t + s, x âˆ’ y).
2
Lemma A.5 (Lemma 4.4 of [11]). For all x, z1 z2 âˆˆ R and t, s > 0, denote zÌ„ = z1 +z
,
2
(4t)âˆ¨s
âˆ†z = z1 âˆ’ z2 . Then G1 (t, x âˆ’ zÌ„) G1 (s, âˆ†z) â‰¤ âˆšts G1 ((4t) âˆ¨ s, x âˆ’ z1 ) G1 ((4t) âˆ¨ s, x âˆ’ z2 ),
where a âˆ¨ b := max(a, b).

References
[1] R. Balan and D. Conus. Intermittency for the wave and heat equations with fractional
noise in time. Preprint at arXiv::1311.0021, 2013.
[2] L. Bertini and N. Cancrini. The stochastic heat equation: Feynman-Kac formula and
intermittence. J. Statist. Phys., 78(5-6):1377â€“1401, 1995.
[3] P. Billingsley. Probability and measure (3rd ed.). John Wiley & Sons Inc., New York,
1995.
[4] Z. BrzezÌniak and M. OndrejaÌt. Strong solutions to stochastic wave equations with values
in Riemannian manifolds. J. Funct. Anal., 253(2):449â€“481, 2007.
[5] Z. BrzezÌniak and M. OndrejaÌt. Weak solutions to stochastic wave equations with values
in Riemannian manifolds. Comm. Partial Differential Equations, 36(9):1624â€“1653, 2011.
47

[6] R. Cairoli and J. B. Walsh. Stochastic integrals in the plane. Acta Math., 134:111â€“183,
1975.
[7] R. A. Carmona and S. A. Molchanov. Parabolic Anderson problem and intermittency.
Mem. Amer. Math. Soc., 108(518), 1994.
[8] R. A. Carmona and D. Nualart. Random nonlinear wave equations: propagation of
singularities. Ann. Probab., 16(2):730â€“751, 1988.
[9] R. Carmona and D. Nualart. Random nonlinear wave equations: smoothness of the
solutions. Probab. Theory Related Fields, 79(4):469â€“508, 1988.
[10] L. Chen. Moments, intermittency, and growth indices for nonlinear stochastic PDEâ€™s
with rough initial conditions. PhD thesis, No. 5712, EÌcole Polytechnique FeÌdeÌrale de
Lausanne, 2013.
[11] L. Chen and R. C. Dalang. Moments and growth indices for the nonlinear stochastic
heat equation with rough initial conditions. Preprint at arXiv:1307.0600, 2013.
[12] L. Chen and R. C. Dalang. HoÌˆlder-continuity for the nonlinear stochastic heat equation
with rough initial conditions. Preprint at arXiv::1310.6421, 2013.
[13] P.-L. Chow. Stochastic wave equations with polynomial nonlinearity. Ann. Appl.
Probab., 12(1):361â€“381, 2002.
[14] K. L. Chung and R. J. Williams. Introduction to stochastic integration (2nd ed.).
BirkhaÌˆuser Boston Inc., Boston, MA, 1990.
[15] D. Conus and R. C. Dalang. The non-linear stochastic wave equation in high dimensions.
Electron. J. Probab., 13:no. 22, 629â€“670, 2008.
[16] D. Conus, M. Joseph, D. Khoshnevisan, and S.-Y. Shiu. Initial measures for the stochastic heat equation. Ann. Inst. Henri PoincareÌ Probab. Stat., to appear, 2013.
[17] D. Conus, M. Joseph, D. Khoshnevisan, and S.-Y. Shiu. Intermittency and chaos for a
stochastic non-linear wave equation in dimension 1. Preprint at arXiv:112.1909, 2011.
[18] D. Conus and D. Khoshnevisan. On the existence and position of the farthest peaks of
a family of stochastic heat and wave equations. Probab. Theory Related Fields, 152(34):681â€“701, 2012.
[19] R. Dalang, D. Khoshnevisan, C. Mueller, D. Nualart, and Y. Xiao. A minicourse on
stochastic partial differential equations. Springer-Verlag, Berlin, 2009.
[20] R. C. Dalang. The stochastic wave equation. Chapter 2 in [19].

48

[21] R. C. Dalang. Extending the martingale measure stochastic integral with applications
to spatially homogeneous s.p.d.e.â€™s. Electron. J. Probab., 4:no. 6, 29 pp. (electronic),
1999.
[22] R. C. Dalang and N. E. Frangos. The stochastic wave equation in two spatial dimensions.
Ann. Probab., 26(1):187â€“212, 1998.
[23] R. C. Dalang and C. Mueller. Intermittency properties in a hyperbolic Anderson problem. Ann. Inst. Henri PoincareÌ Probab. Stat., 45(4):1150â€“1164, 2009.
[24] R. C. Dalang, C. Mueller, and R. Tribe. A Feynman-Kac-type formula for the deterministic and stochastic wave equations and other P.D.E.â€™s. Trans. Amer. Math. Soc.,
360(9):4681â€“4703, 2008.
[25] R. C. Dalang and L. Quer-Sardanyons. Stochastic integrals for spdeâ€™s: a comparison.
Expo. Math., 29(1):67â€“109, 2011.
[26] R. C. Dalang and M. Sanz-SoleÌ. HoÌˆlder-Sobolev regularity of the solution to the stochastic wave equation in dimension three. Mem. Amer. Math. Soc., 199(931), 2009.
[27] EÌ€Ä±Ì†del0 man, S. D. Parabolic systems (Translated from the Russian by Scripta Technica,
London). North-Holland Publishing Co., Amsterdam, 1969.
[28] A. ErdeÌlyi, W. Magnus, F. Oberhettinger, and F. G. Tricomi. Tables of integral transforms. Vol. II. McGraw-Hill Book Company, Inc., New York-Toronto-London, 1954.
[29] M. Foondun and D. Khoshnevisan. Intermittence and nonlinear parabolic stochastic
partial differential equations. Electron. J. Probab., 14:no. 21, 548â€“568, 2009.
[30] A. Friedman. Generalized functions and partial differential equations Prentice-Hall,
Englewood Cliffs, New Jersey, 1963.
[31] A. Friedman. Partial differential equations of parabolic type Prentice-Hall, Inc., Englewood Cliffs, N.J. 1964.
[32] J. Kevorkian. Partial differential equations: analytical solution techniques. SpringerVerlag, New York, 2000.
[33] H. Kunita. Stochastic flows and stochastic differential equations. Cambridge University
Press, Cambridge, 1990.
[34] H.-H. Kuo. Introduction to stochastic integration. Springer, New York, 2006.
[35] A. Millet and P.-L. Morien. On a nonlinear stochastic wave equation in the plane:
existence and uniqueness of the solution. Ann. Appl. Probab., 11(3):922â€“951, 2001.

49

[36] A. Millet and M. Sanz-SoleÌ. A stochastic wave equation in two space dimension: smoothness of the law. Ann. Probab., 27(2):803â€“844, 1999.
[37] D. Nualart and L. Quer-Sardanyons. Existence and smoothness of the density for spatially homogeneous SPDEs. Potential Anal., 27(3):281â€“299, 2007.
[38] F. W. J. Olver, D. W. Lozier, R. F. Boisvert, and C. W. Clark, editors. NIST handbook of
mathematical functions. U.S. Department of Commerce National Institute of Standards
and Technology, Washington, DC, 2010.
[39] M. OndrejaÌt. Stochastic nonlinear wave equations in local Sobolev spaces. Electron. J.
Probab., 15:no. 33, 1041â€“1091, 2010.
[40] M. OndrejaÌt. Stochastic wave equation with critical nonlinearities: temporal regularity
and uniqueness. J. Differential Equations, 248(7):1579â€“1602, 2010.
[41] E. Orsingher. Randomly forced vibrations of a string. Ann. Inst. H. PoincareÌ Sect. B
(N.S.), 18(4):367â€“394, 1982.
[42] S. Peszat. The Cauchy problem for a nonlinear stochastic wave equation in any dimension. J. Evol. Equ., 2(3):383â€“394, 2002.
[43] S. Peszat and J. Zabczyk. Stochastic evolution equations with a spatially homogeneous
Wiener process. Stochastic Process. Appl., 72(2):187â€“204, 1997.
[44] L. Quer-Sardanyons and M. Sanz-SoleÌ. A stochastic wave equation in dimension 3:
smoothness of the law. Bernoulli, 10(1):165â€“186, 2004.
[45] M. Sanz-SoleÌ and M. SarraÌ€. Path properties of a class of Gaussian processes with
applications to spdeâ€™s. In Stochastic processes, physics and geometry: new interplays, I
(Leipzig, 1999), pages 303â€“316. Amer. Math. Soc., Providence, RI, 2000.
[46] J. B. Walsh. An introduction to stochastic partial differential equations. In EÌcole dâ€™eÌteÌ
de probabiliteÌs de Saint-Flour, XIVâ€”1984, pages 265â€“439. Springer, Berlin, 1986.
[47] G. N. Watson. A Treatise on the Theory of Bessel Functions. Cambridge University
Press, Cambridge, England, 1944.

50

